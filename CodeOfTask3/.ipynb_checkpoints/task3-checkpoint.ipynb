{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# GAMMA Challenge Subtask 3 - Optic Disc and Cup Segmentation - Marco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 429\u001b[0m\n\u001b[1;32m    427\u001b[0m ap\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--mode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, choices\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_e\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    428\u001b[0m ap\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--weights\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_models_torch/best_model_0.9000/model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 429\u001b[0m args, _ \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241m.\u001b[39mparse_known_args()  \u001b[38;5;66;03m# ✅ 忽略掉 Jupyter 自动加的参数\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m#args = ap.parse_args()\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parser' is not defined"
     ]
    }
   ],
   "source": [
    "# test3_torch.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "PyTorch rewrite of Paddle code (fundus disc/cup segmentation).\n",
    "- Dataset, model (SeparableConv UNet), losses (Dice variants), train/val, inference\n",
    "- No Paddle dependencies\n",
    "\"\"\"\n",
    "\n",
    "import os, cv2, random, argparse, math, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ----------------------- Config -----------------------\n",
    "images_file = '/home/yanggq/project/grading/Glaucoma_grading/training/multi-modality_images'  # fundus image root\n",
    "gt_file     = '/home/yanggq/project/grading/task3_disc_cup_segmentation/training/Disc_Cup_Mask'  # mask root\n",
    "val_ratio   = 0.1\n",
    "image_size  = 512\n",
    "BATCH_SIZE  = 8\n",
    "iters       = 20000\n",
    "optimizer_type = 'adam'\n",
    "num_workers = 8\n",
    "init_lr     = 1e-3\n",
    "save_dir    = \"trained_models_torch\"\n",
    "\n",
    "# ------------------- Simple paired transforms -------------------\n",
    "def center_crop(img, size_hw):\n",
    "    h, w = img.shape[:2]\n",
    "    th, tw = size_hw\n",
    "    th = min(th, h); tw = min(tw, w)\n",
    "    i = (h - th)//2; j = (w - tw)//2\n",
    "    return img[i:i+th, j:j+tw]\n",
    "\n",
    "def resize_image(img, size_hw, is_mask=False):\n",
    "    interp = cv2.INTER_NEAREST if is_mask else cv2.INTER_LINEAR\n",
    "    return cv2.resize(img, (size_hw[1], size_hw[0]), interpolation=interp)\n",
    "\n",
    "def random_hflip_pair(img, mask, p=0.5):\n",
    "    if random.random() < p:\n",
    "        img  = img[:, ::-1].copy()\n",
    "        mask = mask[:, ::-1].copy()\n",
    "    return img, mask\n",
    "\n",
    "def random_vflip_pair(img, mask, p=0.5):\n",
    "    if random.random() < p:\n",
    "        img  = img[::-1, :].copy()\n",
    "        mask = mask[::-1, :].copy()\n",
    "    return img, mask\n",
    "\n",
    "def random_rotate_pair(img, mask, deg=60):\n",
    "    angle = random.uniform(-deg, deg)\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "    img2  = cv2.warpAffine(img,  M, (w, h), flags=cv2.INTER_LINEAR,  borderMode=cv2.BORDER_REFLECT_101)\n",
    "    mask2 = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_REFLECT_101)\n",
    "    return img2, mask2\n",
    "\n",
    "# ----------------------- Dataset -----------------------\n",
    "class FundusDataset(Dataset):\n",
    "    \"\"\"\n",
    "    images_file/ID/ID.jpg\n",
    "    gt_file/ID.png  (values: 0=cup, 128=disc, 255=background)\n",
    "    Returns (for train/val):\n",
    "      img: float32 [3,H,W] in [0,1]\n",
    "      mask: int64  [H,W] with classes {0,1,2}\n",
    "    For test:\n",
    "      (img, id, orig_h, orig_w)\n",
    "    \"\"\"\n",
    "    def __init__(self, image_file, gt_path=None, filelists=None, mode='train',\n",
    "                 do_aug=True, img_size=512):\n",
    "        super().__init__()\n",
    "        self.image_file = image_file\n",
    "        self.gt_path = gt_path\n",
    "        self.mode = mode.lower()\n",
    "        self.do_aug = do_aug and (self.mode=='train')\n",
    "        self.img_size = img_size\n",
    "\n",
    "        ids = sorted(os.listdir(self.image_file))\n",
    "        if filelists is not None:\n",
    "            keep = set(filelists)\n",
    "            ids = [i for i in ids if i in keep]\n",
    "        self.ids = ids\n",
    "\n",
    "    def __len__(self): return len(self.ids)\n",
    "\n",
    "    def _read_img(self, idx):\n",
    "        p = os.path.join(self.image_file, idx, f\"{idx}.jpg\")\n",
    "        im = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "        if im is None: raise FileNotFoundError(p)\n",
    "        return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def _read_mask(self, idx):\n",
    "        p = os.path.join(self.gt_path, f\"{idx}.png\")\n",
    "        m = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        if m is None: raise FileNotFoundError(p)\n",
    "        # Map values: 0->0 (cup), 128->1 (disc), 255->2 (bg)\n",
    "        mask = np.zeros_like(m, dtype=np.uint8)\n",
    "        mask[m==0]   = 0\n",
    "        mask[m==128] = 1\n",
    "        mask[m==255] = 2\n",
    "        return mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.ids[i]\n",
    "        img = self._read_img(idx)\n",
    "        h0, w0 = img.shape[:2]\n",
    "\n",
    "        # center crop to square, then resize\n",
    "        s = min(h0, w0)\n",
    "        img = center_crop(img, (s, s))\n",
    "        img = resize_image(img, (self.img_size, self.img_size), is_mask=False)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            img_t = torch.from_numpy(img.astype(np.float32).transpose(2,0,1) / 255.0)\n",
    "            return img_t, idx, h0, w0\n",
    "\n",
    "        mask = self._read_mask(idx)\n",
    "        mask = center_crop(mask, (s, s))\n",
    "        mask = resize_image(mask, (self.img_size, self.img_size), is_mask=True)\n",
    "\n",
    "        if self.do_aug:\n",
    "            img, mask = random_hflip_pair(img, mask, 0.5)\n",
    "            img, mask = random_vflip_pair(img, mask, 0.5)\n",
    "            img, mask = random_rotate_pair(img, mask, 60)\n",
    "\n",
    "        img_t  = torch.from_numpy(img.astype(np.float32).transpose(2,0,1)/255.0)\n",
    "        mask_t = torch.from_numpy(mask.astype(np.int64))\n",
    "        return img_t, mask_t\n",
    "\n",
    "# ----------------------- Model -----------------------\n",
    "class SeparableConv2D(nn.Module):\n",
    "    \"\"\"Depthwise separable conv: depthwise + pointwise\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3, stride=1, padding=1, dilation=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size, stride, padding, dilation,\n",
    "                                   groups=in_ch, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=bias)\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.sep1  = SeparableConv2D(in_channels, out_channels, 3, 1, 1)\n",
    "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.sep2  = SeparableConv2D(out_channels, out_channels, 3, 1, 1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.pool  = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.residual = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.residual(x)\n",
    "        y = self.relu1(x)\n",
    "        y = self.sep1(y); y = self.bn1(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.sep2(y); y = self.bn2(y)\n",
    "        y = self.pool(y)\n",
    "        return y + res\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.deconv2 = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.ups   = nn.Upsample(scale_factor=2.0, mode='bilinear', align_corners=False)\n",
    "        self.res_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.ups(self.res_conv(x))\n",
    "        y = self.relu1(x)\n",
    "        y = self.deconv1(y); y = self.bn1(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.deconv2(y); y = self.bn2(y)\n",
    "        y = self.ups(y)\n",
    "        return y + res\n",
    "\n",
    "class CupDiscUNet(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(32)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        # encoders\n",
    "        in_channels = 32\n",
    "        self.encoders = nn.ModuleList()\n",
    "        for out_ch in [64,128,256]:\n",
    "            self.encoders.append(Encoder(in_channels, out_ch))\n",
    "            in_channels = out_ch\n",
    "        # decoders\n",
    "        self.decoders = nn.ModuleList()\n",
    "        for out_ch in [256,128,64,32]:\n",
    "            self.decoders.append(Decoder(in_channels, out_ch))\n",
    "            in_channels = out_ch\n",
    "        self.head = nn.Conv2d(in_channels, num_classes, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.relu(self.bn1(self.conv1(x)))\n",
    "        for enc in self.encoders:\n",
    "            y = enc(y)\n",
    "        for dec in self.decoders:\n",
    "            y = dec(y)\n",
    "        y = self.head(y)\n",
    "        return y  # logits [N,C,H,W]\n",
    "\n",
    "# ----------------------- Losses -----------------------\n",
    "def one_hot(labels, num_classes):\n",
    "    # labels: [N,H,W] int64\n",
    "    n, h, w = labels.size(0), labels.size(1), labels.size(2)\n",
    "    y = torch.zeros((n, num_classes, h, w), device=labels.device, dtype=torch.float32)\n",
    "    return y.scatter_(1, labels.unsqueeze(1), 1.0)\n",
    "\n",
    "class DiceMetric(nn.Module):\n",
    "    \"\"\"As metric (softmax->prob), returns mean Dice over classes\"\"\"\n",
    "    def __init__(self, eps=1e-5, ignore_index=None):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.ignore_index = ignore_index\n",
    "    def forward(self, logits, labels):\n",
    "        num_classes = logits.shape[1]\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        if self.ignore_index is not None:\n",
    "            mask = (labels != self.ignore_index).float()\n",
    "            probs = probs * mask.unsqueeze(1)\n",
    "        labels_1h = one_hot(labels.clamp_min(0), num_classes)\n",
    "        inter = torch.sum(probs * labels_1h, dim=(0,2,3))\n",
    "        card  = torch.sum(probs + labels_1h, dim=(0,2,3))\n",
    "        dice = (2*inter / (card + self.eps)).mean()\n",
    "        return dice\n",
    "\n",
    "class MinusDiceLoss(nn.Module):\n",
    "    \"\"\"1 - Dice(probs, onehot)\"\"\"\n",
    "    def __init__(self, eps=1e-5, ignore_index=None):\n",
    "        super().__init__()\n",
    "        self.metric = DiceMetric(eps, ignore_index)\n",
    "    def forward(self, logits, labels):\n",
    "        return 1.0 - self.metric(logits, labels)\n",
    "\n",
    "class DiceFromArgmax(nn.Module):\n",
    "    \"\"\"Replicates your MinusDiceLoss2/DiceLoss2 behavior using argmax masks.\n",
    "       Weights: cup 0.30, disc 0.42, bg 0.28 (as in your code).\"\"\"\n",
    "    def __init__(self, weights=(0.30, 0.42, 0.28), eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.w = torch.tensor(weights, dtype=torch.float32)\n",
    "        self.eps = eps\n",
    "    def forward(self, logits, labels):\n",
    "        # logits -> hard mask\n",
    "        pred = torch.argmax(logits, dim=1)  # [N,H,W]\n",
    "        num_classes = logits.shape[1]\n",
    "        # one-hot both\n",
    "        pred_1h = one_hot(pred, num_classes).float()\n",
    "        labels_1h = one_hot(labels, num_classes).float()\n",
    "        inter = torch.sum(pred_1h * labels_1h, dim=(0,2,3))\n",
    "        card  = torch.sum(pred_1h + labels_1h, dim=(0,2,3))\n",
    "        dice_per_class = (2*inter / (card + self.eps))\n",
    "        # pad weights if needed\n",
    "        w = self.w.to(dice_per_class.device)\n",
    "        if w.numel() != dice_per_class.numel():\n",
    "            w = torch.ones_like(dice_per_class) / dice_per_class.numel()\n",
    "        dice = torch.sum(w * dice_per_class)\n",
    "        return 1.0 - dice  # as loss\n",
    "\n",
    "# ----------------------- Train / Val -----------------------\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion_loss, criterion_metric, device):\n",
    "    model.eval()\n",
    "    losses, dices = [], []\n",
    "    for img, mask in loader:\n",
    "        img = img.to(device); mask = mask.to(device)\n",
    "        logits = model(img)\n",
    "        loss = criterion_loss(logits, mask)\n",
    "        metric = 1.0 - DiceFromArgmax()(logits, mask) if isinstance(criterion_metric, DiceFromArgmax) else criterion_metric(logits, mask)\n",
    "        losses.append(loss.item())\n",
    "        dices.append(metric.item())\n",
    "    return float(np.mean(losses)), float(np.mean(dices))\n",
    "\n",
    "def train_loop(args):\n",
    "    # split\n",
    "    filelists = sorted(os.listdir(images_file))\n",
    "    train_ids, val_ids = train_test_split(filelists, test_size=val_ratio, random_state=42)\n",
    "    print(f\"Total Nums: {len(filelists)}, train: {len(train_ids)}, val: {len(val_ids)}\")\n",
    "    print(\"val sample:\", val_ids[:10])\n",
    "\n",
    "    train_ds = FundusDataset(images_file, gt_file, filelists=train_ids, mode='train', do_aug=True, img_size=image_size)\n",
    "    val_ds   = FundusDataset(images_file, gt_file, filelists=val_ids,   mode='val',   do_aug=False, img_size=image_size)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "    model = CupDiscUNet(num_classes=3).to(device)\n",
    "\n",
    "    if optimizer_type.lower() == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=init_lr, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    # You used CrossEntropyLoss(axis=1) + Dice metric; keep that.\n",
    "    criterion_loss = nn.CrossEntropyLoss()\n",
    "    # Your metric DiceLoss2 approximates dice on argmax with class weights -> use DiceFromArgmax\n",
    "    criterion_metric = DiceFromArgmax(weights=(0.30,0.42,0.28))\n",
    "\n",
    "    best_dice = -1e9\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    it = 0\n",
    "    model.train()\n",
    "    avg_loss_buf, avg_dice_buf = [], []\n",
    "    while it < iters:\n",
    "        for img, mask in train_loader:\n",
    "            it += 1\n",
    "            img = img.to(device, non_blocking=True)\n",
    "            mask = mask.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(img)\n",
    "            loss = criterion_loss(logits, mask)\n",
    "            metric_val = 1.0 - DiceFromArgmax()(logits, mask)  # convert to \"dice\" for logging\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            avg_loss_buf.append(loss.item())\n",
    "            avg_dice_buf.append(metric_val.item())\n",
    "\n",
    "            if it % 32 == 0:\n",
    "                avg_loss = float(np.mean(avg_loss_buf)); avg_loss_buf.clear()\n",
    "                avg_dice = float(np.mean(avg_dice_buf)); avg_dice_buf.clear()\n",
    "                print(f\"[TRAIN] iter={it}/{iters} avg_loss={avg_loss:.4f} avg_dice={avg_dice:.4f}\")\n",
    "\n",
    "            if it % 160 == 0:\n",
    "                vloss, vdice = evaluate(model, val_loader, criterion_loss, criterion_metric, device)\n",
    "                print(f\"[EVAL ] iter={it}/{iters} avg_loss={vloss:.4f} dice={vdice:.4f}\")\n",
    "                if vdice >= best_dice:\n",
    "                    best_dice = vdice\n",
    "                    out_dir = os.path.join(save_dir, f\"best_model_{best_dice:.4f}\")\n",
    "                    os.makedirs(out_dir, exist_ok=True)\n",
    "                    torch.save(model.state_dict(), os.path.join(out_dir, \"model.pt\"))\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(out_dir, \"optimizer.pt\"))\n",
    "                    print(\"[SAVE ]\", out_dir)\n",
    "                model.train()\n",
    "\n",
    "            if it >= iters:\n",
    "                break\n",
    "\n",
    "# ----------------------- Visualization eval (single batch) -----------------------\n",
    "@torch.no_grad()\n",
    "def val_e(weights_path, val_ids=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CupDiscUNet(num_classes=3).to(device)\n",
    "    state = torch.load(weights_path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    if val_ids is None:\n",
    "        val_ids = ['0016']\n",
    "\n",
    "    ds = FundusDataset(images_file, gt_file, filelists=val_ids, mode='val', do_aug=False, img_size=image_size)\n",
    "    dl = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    for img, mask in dl:\n",
    "        img = img.to(device)\n",
    "        logits = model(img)\n",
    "        pred = torch.argmax(logits, dim=1)[0].cpu().numpy().astype(np.float32)\n",
    "        gt   = mask[0].cpu().numpy().astype(np.float32)\n",
    "\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(1,3,1); plt.title(\"GT\");   plt.imshow(gt, cmap='gray')\n",
    "        plt.subplot(1,3,2); plt.title(\"Pred\"); plt.imshow(pred, cmap='gray')\n",
    "        # simple overlay\n",
    "        rgb = (img[0].cpu().numpy().transpose(1,2,0)*255).astype(np.uint8)\n",
    "        overlay = rgb.copy()\n",
    "        overlay[pred==1] = (0,255,0)\n",
    "        overlay[pred==2] = (255,0,0)\n",
    "        plt.subplot(1,3,3); plt.title(\"Overlay\"); plt.imshow(overlay); plt.tight_layout(); plt.show()\n",
    "\n",
    "# ----------------------- Inference (save BMP masks) -----------------------\n",
    "@torch.no_grad()\n",
    "def infer_to_bmp(weights_path, test_path='val_data/multi-modality_images', out_dir='Disc_Cup_Segmentations'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CupDiscUNet(num_classes=3).to(device)\n",
    "    state = torch.load(weights_path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    ds = FundusDataset(test_path, gt_path=None, filelists=None, mode='test', do_aug=False, img_size=image_size)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    ids = sorted(os.listdir(test_path))\n",
    "    print(ids)\n",
    "    for img, idx, h, w in ds:\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        logits = model(img)\n",
    "        pred = torch.argmax(logits, dim=1)[0].cpu().numpy().astype(np.float32)\n",
    "        # map back to 0/128/255 palette\n",
    "        pred[pred==1] = 128\n",
    "        pred[pred==2] = 255\n",
    "        # resize back to square min(h,w), then pad to original like original code\n",
    "        min_side = min(h, w)\n",
    "        pred_sq = cv2.resize(pred, (min_side, min_side), interpolation=cv2.INTER_NEAREST)\n",
    "        padding = (max(h,w) - min(h,w))//2\n",
    "        if h >= w:\n",
    "            # pad left/right\n",
    "            pad_l = padding; pad_r = max(h,w) - min(h,w) - pad_l\n",
    "            pred_full = cv2.copyMakeBorder(pred_sq, 0, 0, pad_l, pad_r, cv2.BORDER_CONSTANT, value=255)\n",
    "        else:\n",
    "            # pad top/bottom\n",
    "            pad_t = padding; pad_b = max(h,w) - min(h,w) - pad_t\n",
    "            pred_full = cv2.copyMakeBorder(pred_sq, pad_t, pad_b, 0, 0, cv2.BORDER_CONSTANT, value=255)\n",
    "        cv2.imwrite(os.path.join(out_dir, f\"{idx}.bmp\"), pred_full)\n",
    "\n",
    "# ----------------------- Main -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--mode\", type=str, default=\"train\", choices=[\"train\",\"val_e\",\"infer\"])\n",
    "    ap.add_argument(\"--weights\", type=str, default=\"trained_models_torch/best_model_0.9000/model.pt\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        train_loop(args)\n",
    "    elif args.mode == \"val_e\":\n",
    "        val_e(args.weights, val_ids=['0016'])\n",
    "    else:\n",
    "        infer_to_bmp(args.weights, test_path='val_data/multi-modality_images', out_dir='Disc_Cup_Segmentations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
