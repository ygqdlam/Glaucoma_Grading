{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec284a-b069-4650-85af-2635a5299d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Total Nums: 100, train: 80, val: 20\n",
      "labels sample: [1 0 1 2] dtype: int64 shape: (4,)\n",
      "[TRAIN] iter=10/1000 avg_loss=0.8505 avg_kappa=0.4891\n",
      "[TRAIN] iter=20/1000 avg_loss=0.8039 avg_kappa=0.5701\n",
      "[TRAIN] iter=30/1000 avg_loss=0.8512 avg_kappa=0.5565\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "from torchvision.models import resnet34, resnet50\n",
    "\n",
    "# 如果你有自定义 transforms（保持你原来的 API）\n",
    "import transforms as trans   # 若没有这份文件，可自行改用 torchvision.transforms\n",
    "\n",
    "# ========= 基本配置 =========\n",
    "batchsize    = 4\n",
    "oct_img_size = [512, 512]\n",
    "image_size   = 256\n",
    "iters        = 10000\n",
    "val_ratio    = 0.2\n",
    "trainset_root = \"/home/yanggq/project/grading/Glaucoma_grading/training/multi-modality_images\"\n",
    "label_xlsx    = \"/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx\"\n",
    "num_workers   = 4\n",
    "init_lr       = 1e-4\n",
    "save_dir      = \"trained_models_torch\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ========= 数据集 =========\n",
    "class GAMMA_sub1_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    输出:\n",
    "      fundus_img: uint8, shape (3, H, W) - RGB\n",
    "      oct_img   : uint8, shape (D, H, W) - 灰度体数据 (把 D 当做通道数用在 2D ResNet 上)\n",
    "      label     : int64 标量（0..C-1）\n",
    "    \"\"\"\n",
    "    def __init__(self, img_transforms, oct_transforms, dataset_root,\n",
    "                 label_file='', filelists=None, num_classes=3, mode='train'):\n",
    "        self.dataset_root   = dataset_root\n",
    "        self.img_transforms = img_transforms\n",
    "        self.oct_transforms = oct_transforms\n",
    "        self.mode           = mode.lower()\n",
    "        self.num_classes    = num_classes\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            # 你原始脚本从 xlsx 里读 one-hot/prob 向量，这里保持一致\n",
    "            # 注意：确保读到的是 float 数组\n",
    "            label_map = {\n",
    "                int(row['data']): np.asarray(row[1:].values, dtype=np.float32)\n",
    "                for _, row in pd.read_excel(label_file).iterrows()\n",
    "            }\n",
    "            self.file_list = [[f, label_map[int(f)]] for f in os.listdir(dataset_root)]\n",
    "        else:\n",
    "            self.file_list = [[f, None] for f in os.listdir(dataset_root)]\n",
    "\n",
    "        if filelists is not None:\n",
    "            name_set = set(filelists)\n",
    "            self.file_list = [it for it in self.file_list if it[0] in name_set]\n",
    "\n",
    "    def _oct_sort_key(self, name: str):\n",
    "        # 你原脚本用 int(x.strip(\"_\")[0]) 会按第一个字符排序，10 与 2 会乱序\n",
    "        stem = os.path.splitext(name)[0]\n",
    "        m = re.search(r'(\\d+)$', stem)\n",
    "        return int(m.group(1)) if m else stem  # 更稳妥\n",
    "        # 参考你原代码位置：oct_series_list 的排序逻辑。:contentReference[oaicite:3]{index=3}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_index, label_vec = self.file_list[idx]\n",
    "\n",
    "        fundus_img_path = os.path.join(self.dataset_root, real_index, real_index + \".jpg\")\n",
    "        series_dir = os.path.join(self.dataset_root, real_index, real_index)\n",
    "        oct_series_list = sorted(os.listdir(series_dir), key=self._oct_sort_key)\n",
    "\n",
    "        fundus_img = cv2.imread(fundus_img_path)[:, :, ::-1]  # BGR->RGB\n",
    "        # 装载一组 OCT 切片\n",
    "        oct0 = cv2.imread(os.path.join(series_dir, oct_series_list[0]), cv2.IMREAD_GRAYSCALE)\n",
    "        D, H, W = len(oct_series_list), oct0.shape[0], oct0.shape[1]\n",
    "        oct_img = np.zeros((D, H, W, 1), dtype=\"uint8\")\n",
    "        for k, p in enumerate(oct_series_list):\n",
    "            oct_img[k] = cv2.imread(os.path.join(series_dir, p), cv2.IMREAD_GRAYSCALE)[..., np.newaxis]\n",
    "\n",
    "        # 可选的图像增强\n",
    "        if self.img_transforms is not None:\n",
    "            fundus_img = self.img_transforms(fundus_img)\n",
    "        if self.oct_transforms is not None:\n",
    "            oct_img = self.oct_transforms(oct_img)\n",
    "\n",
    "        # NHWC -> NCHW\n",
    "        fundus_img = fundus_img.transpose(2, 0, 1)  # (H,W,C)->(C,H,W)\n",
    "        oct_img    = oct_img.squeeze(-1)            # (D,H,W,1)->(D,H,W)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return fundus_img, oct_img, real_index\n",
    "\n",
    "        # —— 标签：只 argmax 一次，返回 np.int64 标量（修复你原代码的“双重 argmax”问题）——\n",
    "        # 参考处：你原脚本 L61-L64 同时做了 label.argmax() 和 np.argmax(label)，会出错。:contentReference[oaicite:4]{index=4}\n",
    "        class_id = np.int64(np.argmax(label_vec))\n",
    "        return fundus_img, oct_img, class_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "# ========= collate：显式堆叠，避免默认逻辑把标签搞坏 =========\n",
    "def my_collate(batch):\n",
    "    f_list, o_list, y_list = zip(*batch)\n",
    "    f = np.stack(f_list, axis=0).astype('uint8')     # [N,3,H,W]\n",
    "    o = np.stack(o_list, axis=0).astype('uint8')     # [N,D,H,W]\n",
    "    y = np.asarray(y_list, dtype=np.int64)           # [N]\n",
    "    return f, o, y\n",
    "\n",
    "# ========= transforms（按你原脚本）=========\n",
    "img_train_transforms = trans.Compose([\n",
    "    trans.RandomResizedCrop(image_size, scale=(0.90, 1.1), ratio=(0.90, 1.1)),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "    trans.RandomRotation(30),\n",
    "])\n",
    "oct_train_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "])\n",
    "img_val_transforms = trans.Compose([\n",
    "    trans.CropCenterSquare(),\n",
    "    trans.Resize((image_size, image_size)),\n",
    "])\n",
    "oct_val_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size),\n",
    "])\n",
    "\n",
    "# ========= 划分数据 =========\n",
    "filelists = os.listdir(trainset_root)\n",
    "#train_filelists, val_filelists = train_test_split(filelists, test_size=val_ratio, random_state=12)\n",
    "\n",
    "# 最后 20 个作为测试集\n",
    "val_filelists = filelists[-20:]\n",
    "# 其余的作为训练集\n",
    "train_filelists = filelists[:-20]\n",
    "\n",
    "print(f\"Total Nums: {len(filelists)}, train: {len(train_filelists)}, val: {len(val_filelists)}\")\n",
    "\n",
    "\n",
    "train_dataset = GAMMA_sub1_dataset(dataset_root=trainset_root, \n",
    "                                   img_transforms=img_train_transforms,\n",
    "                                   oct_transforms=oct_train_transforms,\n",
    "                                   filelists=train_filelists,\n",
    "                                   label_file=label_xlsx)\n",
    "\n",
    "val_dataset = GAMMA_sub1_dataset(dataset_root=trainset_root, \n",
    "                                 img_transforms=img_val_transforms,\n",
    "                                 oct_transforms=oct_val_transforms,\n",
    "                                 filelists=val_filelists,\n",
    "                                 label_file=label_xlsx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True,\n",
    "                          num_workers=num_workers, collate_fn=my_collate, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batchsize, shuffle=False,\n",
    "                          num_workers=num_workers, collate_fn=my_collate, pin_memory=True)\n",
    "\n",
    "# ========= 模型（PyTorch 版）=========\n",
    "class ModelRes34(nn.Module):\n",
    "    \"\"\"\n",
    "    两分支：\n",
    "      - fundus_branch: resnet34 输入 3 通道\n",
    "      - oct_branch   : resnet34 输入 256 通道（把 OCT D 当通道）\n",
    "      - 拼接后接 linear 输出 3 类\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.fundus_branch = resnet34(weights=\"IMAGENET1K_V1\")  # 预训练\n",
    "        self.oct_branch    = resnet34(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "        # 去掉原 fc，改成输出特征\n",
    "        self.fundus_branch.fc = nn.Identity()\n",
    "        self.oct_branch.fc    = nn.Identity()\n",
    "\n",
    "        # 替换 OCT 分支第一层为 256 输入通道（与你 Paddle 版一致）:contentReference[oaicite:5]{index=5}\n",
    "        self.oct_branch.conv1 = nn.Conv2d(256, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # resnet34 的全局池化+fc 前输出 512 维；两分支拼接后变 1024\n",
    "        self.fc = nn.Linear(512 * 2, num_classes)\n",
    "\n",
    "    def forward(self, fundus_img, oct_img):\n",
    "        # fundus_img: [N,3,H,W] float\n",
    "        # oct_img   : [N,256,H,W] float\n",
    "        b1 = self.fundus_branch(fundus_img)  # [N,512]\n",
    "        b2 = self.oct_branch(oct_img)        # [N,512]\n",
    "        logit = self.fc(torch.cat([b1, b2], dim=1))  # [N,3]\n",
    "        return logit\n",
    "\n",
    "model = ModelRes34(num_classes=3).to(device)\n",
    "\n",
    "# ========= 优化器 / 损失 =========\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ========= 训练 / 验证 =========\n",
    "def tensorize_batch(batch):\n",
    "    f, o, y = batch  # numpy\n",
    "    # 转 float32 Tensor；归一化到 [0,1]\n",
    "    fundus = torch.from_numpy(f).float().div_(255.0).to(device, non_blocking=True)  # [N,3,H,W]\n",
    "    octv   = torch.from_numpy(o).float().div_(255.0).to(device, non_blocking=True)  # [N,D,H,W]\n",
    "    # 把 D 作为通道，输入 2D ResNet：[N,256,H,W]\n",
    "    # 你的 Dataset 已经输出 [D,H,W]，collate 后是 [N,D,H,W]，无需再转置\n",
    "    labels = torch.from_numpy(y).long().to(device, non_blocking=True)               # [N]\n",
    "    return fundus, octv, labels\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    preds_all, gts_all = [], []\n",
    "    for batch in val_loader:\n",
    "        fundus, octv, labels = tensorize_batch(batch)\n",
    "        logits = model(fundus, octv)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        gts   = labels.cpu().numpy()\n",
    "        preds_all.append(preds); gts_all.append(gts)\n",
    "    preds_all = np.concatenate(preds_all, 0)\n",
    "    gts_all   = np.concatenate(gts_all, 0)\n",
    "    kappa = cohen_kappa_score(preds_all, gts_all, weights='quadratic')\n",
    "    return float(np.mean(losses)), float(kappa)\n",
    "\n",
    "def train(num_iters=iters, log_interval=10, eval_interval=100):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.train()\n",
    "    best_kappa = -1e9\n",
    "    avg_loss_buf = []\n",
    "    kappa_buf_p, kappa_buf_g = [], []\n",
    "\n",
    "    it = 0\n",
    "    while it < num_iters:\n",
    "        for batch in train_loader:\n",
    "            it += 1\n",
    "            fundus, octv, labels = tensorize_batch(batch)\n",
    "\n",
    "            logits = model(fundus, octv)  # [N,3]\n",
    "            # 断言标签范围（你之前的致命问题）\n",
    "            with torch.no_grad():\n",
    "                lb_min, lb_max = int(labels.min().item()), int(labels.max().item())\n",
    "                assert 0 <= lb_min and lb_max < logits.size(1), \\\n",
    "                    f\"label out of range [{lb_min},{lb_max}] vs C={logits.size(1)}\"\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            avg_loss_buf.append(loss.item())\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                gts  = labels.cpu().numpy()\n",
    "                kappa_buf_p.append(pred); kappa_buf_g.append(gts)\n",
    "\n",
    "            if it % log_interval == 0:\n",
    "                avg_loss = float(np.mean(avg_loss_buf)); avg_loss_buf.clear()\n",
    "                p = np.concatenate(kappa_buf_p, 0); g = np.concatenate(kappa_buf_g, 0)\n",
    "                kappa = cohen_kappa_score(p, g, weights='quadratic')\n",
    "                kappa_buf_p.clear(); kappa_buf_g.clear()\n",
    "                print(f\"[TRAIN] iter={it}/{num_iters} avg_loss={avg_loss:.4f} avg_kappa={kappa:.4f}\")\n",
    "\n",
    "            if it % eval_interval == 0:\n",
    "                vloss, vkappa = evaluate()\n",
    "                print(f\"[EVAL ] iter={it}/{num_iters} avg_loss={vloss:.4f} kappa={vkappa:.4f}\")\n",
    "                if vkappa >= best_kappa:\n",
    "                    best_kappa = vkappa\n",
    "                    tag = f\"best_model_{best_kappa:.4f}\"\n",
    "                    out_dir = os.path.join(save_dir, tag)\n",
    "                    os.makedirs(out_dir, exist_ok=True)\n",
    "                    torch.save(model.state_dict(), os.path.join(out_dir, \"model.pt\"))\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(out_dir, \"optimizer.pt\"))\n",
    "                    print(f\"[SAVE ] {out_dir}\")\n",
    "                model.train()\n",
    "\n",
    "            if it >= num_iters:\n",
    "                break\n",
    "\n",
    "# ========= 先抽查一个 batch，确认标签健康 =========\n",
    "f0, o0, y0 = next(iter(train_loader))\n",
    "print(\"labels sample:\", y0, \"dtype:\", y0.dtype, \"shape:\", y0.shape)  # 应为 int64、一维、0..2\n",
    "\n",
    "# ========= 开始训练 =========\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f81ce879-bfa6-4853-a6c4-09cdcdff21da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Saved: Classification_Results.csv\n"
     ]
    }
   ],
   "source": [
    "# infer_torch.py\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ==== 配置 ====\n",
    "image_size   = 256\n",
    "oct_img_size = [512, 512]\n",
    "num_classes  = 3\n",
    "\n",
    "# 路径（按需修改）\n",
    "best_model_path = \"/home/yanggq/project/grading/GlaucomaRecognition-main/CodeOfTask1/trained_models_torch/best_model_0.7523/model.pt\"  # PyTorch 权重\n",
    "testset_root    = \"/home/yanggq/project/grading/Glaucoma_grading/training/multi-modality_images\"                    # 测试数据根目录\n",
    "\n",
    "# ==== 轻量 transforms（与你之前的一致风格）====\n",
    "import transforms as trans\n",
    "img_test_transforms = trans.Compose([\n",
    "    trans.CropCenterSquare(),\n",
    "    trans.Resize((image_size, image_size)),\n",
    "])\n",
    "oct_test_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size),\n",
    "])\n",
    "\n",
    "# ==== 测试数据集 ====\n",
    "class GAMMA_sub1_dataset_test(Dataset):\n",
    "    \"\"\"\n",
    "    输出:\n",
    "      fundus_img: uint8, (3, H, W)  RGB\n",
    "      oct_img   : uint8, (D, H, W)  灰度体\n",
    "      idx       : 样本 ID (str)\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_root, img_transforms=None, oct_transforms=None):\n",
    "        self.dataset_root   = dataset_root\n",
    "        self.img_transforms = img_transforms\n",
    "        self.oct_transforms = oct_transforms\n",
    "        self.file_list = sorted(os.listdir(dataset_root))\n",
    "\n",
    "    def _oct_sort_key(self, name: str):\n",
    "        stem = os.path.splitext(name)[0]\n",
    "        m = re.search(r'(\\d+)$', stem)\n",
    "        return int(m.group(1)) if m else stem\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_index = self.file_list[idx]\n",
    "        fundus_img_path = os.path.join(self.dataset_root, real_index, real_index + \".jpg\")\n",
    "        series_dir = os.path.join(self.dataset_root, real_index, real_index)\n",
    "        oct_series_list = sorted(os.listdir(series_dir), key=self._oct_sort_key)\n",
    "\n",
    "        # 读图\n",
    "        fundus_img = cv2.imread(fundus_img_path)[:, :, ::-1]  # BGR->RGB\n",
    "        oct0 = cv2.imread(os.path.join(series_dir, oct_series_list[0]), cv2.IMREAD_GRAYSCALE)\n",
    "        D, H, W = len(oct_series_list), oct0.shape[0], oct0.shape[1]\n",
    "        oct_img = np.zeros((D, H, W, 1), dtype=\"uint8\")\n",
    "        for k, p in enumerate(oct_series_list):\n",
    "            oct_img[k] = cv2.imread(os.path.join(series_dir, p), cv2.IMREAD_GRAYSCALE)[..., np.newaxis]\n",
    "\n",
    "        # transforms\n",
    "        if self.img_transforms is not None:\n",
    "            fundus_img = self.img_transforms(fundus_img)\n",
    "        if self.oct_transforms is not None:\n",
    "            oct_img = self.oct_transforms(oct_img)\n",
    "\n",
    "        # NHWC->CHW / DHWC->DHW\n",
    "        fundus_img = fundus_img.transpose(2, 0, 1)\n",
    "        oct_img    = oct_img.squeeze(-1)\n",
    "\n",
    "        return fundus_img, oct_img, real_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "# ===== collate（显式堆叠，保持 dtype）=====\n",
    "def collate_test(batch):\n",
    "    f_list, o_list, idx_list = zip(*batch)\n",
    "    f = np.stack(f_list, axis=0).astype(\"uint8\")  # [N,3,H,W]\n",
    "    o = np.stack(o_list, axis=0).astype(\"uint8\")  # [N,D,H,W]\n",
    "    return f, o, list(idx_list)\n",
    "\n",
    "# ===== 模型（与你训练用的两分支 ResNet34 对齐）=====\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.fundus_branch = resnet34(weights=\"IMAGENET1K_V1\")\n",
    "        self.oct_branch    = resnet34(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "        # 去掉 fc，只取 512 维特征\n",
    "        self.fundus_branch.fc = nn.Identity()\n",
    "        self.oct_branch.fc    = nn.Identity()\n",
    "\n",
    "        # OCT 分支第一层改为 256 输入通道（把 D 当通道）\n",
    "        self.oct_branch.conv1 = nn.Conv2d(256, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        self.fc = nn.Linear(512 * 2, num_classes)\n",
    "\n",
    "    def forward(self, fundus_img, oct_img):\n",
    "        b1 = self.fundus_branch(fundus_img)  # [N,512]\n",
    "        b2 = self.oct_branch(oct_img)        # [N,512]\n",
    "        return self.fc(torch.cat([b1, b2], dim=1))  # [N, num_classes]\n",
    "\n",
    "# ===== 推理 =====\n",
    "def tensorize_batch(batch, device):\n",
    "    f, o, idx_list = batch\n",
    "    fundus = torch.from_numpy(f).float().div_(255.0).to(device, non_blocking=True)  # [N,3,H,W]\n",
    "    octv   = torch.from_numpy(o).float().div_(255.0).to(device, non_blocking=True)  # [N,D,H,W]\n",
    "    return fundus, octv, idx_list\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    # 数据\n",
    "    test_dataset = GAMMA_sub1_dataset_test(\n",
    "        dataset_root=testset_root,\n",
    "        img_transforms=img_test_transforms,\n",
    "        oct_transforms=oct_test_transforms\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False,\n",
    "                             num_workers=2, collate_fn=collate_test, pin_memory=True)\n",
    "\n",
    "    # 模型 & 权重\n",
    "    model = Model(num_classes=num_classes).to(device)\n",
    "    state = torch.load(best_model_path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    rows = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            fundus, octv, idx_list = tensorize_batch(batch, device)\n",
    "            logits = model(fundus, octv)                   # [N,3]\n",
    "            preds  = torch.argmax(logits, dim=1).cpu().numpy()  # [N]\n",
    "\n",
    "            # 组装提交格式\n",
    "            for i, idx in enumerate(idx_list):\n",
    "                p = int(preds[i])\n",
    "                rows.append([\n",
    "                    idx,\n",
    "                    int(p == 0),  # non\n",
    "                    int(p == 1),  # early\n",
    "                    int(p == 2),  # mid_advanced\n",
    "                ])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"data\", \"non\", \"early\", \"mid_advanced\"])\n",
    "    df.to_csv(\"Classification_Results.csv\", index=False)\n",
    "    print(\"Saved: Classification_Results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6adbab-854c-4a4b-8142-8a511d00d8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa: 0.8113207547169812\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# 读取文件\n",
    "gt_df = pd.read_csv(\"/home/yanggq/project/grading/GlaucomaRecognition-main/CodeOfTask1/Classification_Results.csv\")  # ground truth\n",
    "pred_df = pd.read_excel(\"/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx\")  # predictions\n",
    "\n",
    "# 提取标签（取最大概率对应的类别）\n",
    "gt_labels = gt_df[['non', 'early', 'mid_advanced']].values.argmax(axis=1)\n",
    "pred_labels = pred_df[['non', 'early', 'mid_advanced']].values.argmax(axis=1)\n",
    "\n",
    "# 计算 Cohen's Kappa\n",
    "kappa = cohen_kappa_score(gt_labels, pred_labels)\n",
    "\n",
    "print(\"Cohen's Kappa:\", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73704a0d-53a5-41c8-ae82-d4159675acb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9670, Cohen's Kappa = 0.9470\n",
      "Saved per-sample comparison -> per_sample_compare.csv\n",
      "Wrong samples (head):\n",
      "    data  gt_label  pred_label  is_correct\n",
      "60    70         2           1           0\n",
      "80    90         2           1           0\n",
      "87    97         2           1           0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# 路径按需修改\n",
    "gt_path   = \"/home/yanggq/project/grading/GlaucomaRecognition-main/CodeOfTask1/Classification_Results.csv\"     # 真实标注（Excel）\n",
    "pred_path = \"/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx\"            # 你的预测（CSV）\n",
    "out_path  = \"per_sample_compare.csv\"                # 输出逐样本对比\n",
    "\n",
    "# 1) 读取\n",
    "gt_df   = pd.read_csv(gt_path)                    # 列: data, non, early, mid_advanced\n",
    "pred_df = pd.read_excel(pred_path)                    # 列: data, non, early, mid_advanced\n",
    "\n",
    "# 2) 按 data 对齐（只保留两边都出现过的样本）\n",
    "cols = [\"data\", \"non\", \"early\", \"mid_advanced\"]\n",
    "df = gt_df[cols].merge(pred_df[cols], on=\"data\", suffixes=(\"_gt\", \"_pred\"))\n",
    "\n",
    "# 3) 计算逐样本标签与是否正确\n",
    "gt_labels  = df[[\"non_gt\", \"early_gt\", \"mid_advanced_gt\"]].to_numpy().argmax(axis=1)\n",
    "pred_labels= df[[\"non_pred\",\"early_pred\",\"mid_advanced_pred\"]].to_numpy().argmax(axis=1)\n",
    "\n",
    "per_sample = pd.DataFrame({\n",
    "    \"data\": df[\"data\"],\n",
    "    \"gt_label\":  gt_labels,\n",
    "    \"pred_label\":pred_labels,\n",
    "    \"is_correct\": (gt_labels == pred_labels).astype(int)  # 1=正确，0=错误\n",
    "})\n",
    "\n",
    "# 4) 统计指标（可选）\n",
    "acc   = per_sample[\"is_correct\"].mean()\n",
    "kappa = cohen_kappa_score(gt_labels, pred_labels)\n",
    "print(f\"Accuracy = {acc:.4f}, Cohen's Kappa = {kappa:.4f}\")\n",
    "\n",
    "# 5) 保存逐样本对比\n",
    "per_sample.to_csv(out_path, index=False)\n",
    "print(f\"Saved per-sample comparison -> {out_path}\")\n",
    "\n",
    "# 想看错误样本：\n",
    "errors = per_sample.query(\"is_correct == 0\")\n",
    "print(\"Wrong samples (head):\")\n",
    "print(errors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe005fcf-7c20-4beb-b662-78d2e54060d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-AUC: 0.9006438029109599\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 读取CSV文件\n",
    "gt_path   = \"/home/yanggq/project/grading/GlaucomaRecognition-main/CodeOfTask1/Classification_Results2.csv\"     # 真实标注（Excel）\n",
    "pred_path = \"/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx\"            # 你的预测（CSV）\n",
    "# 1) 读取\n",
    "gt_df   = pd.read_csv(gt_path)                    # 列: data, non, early, mid_advanced\n",
    "pred_df = pd.read_excel(pred_path)                    # 列: data, non, early, mid_advanced\n",
    "\n",
    "# 提取真实标签和预测概率\n",
    "y_true = gt_df[['non', 'early', 'mid_advanced']].values\n",
    "y_pred = pred_df[['non', 'early', 'mid_advanced']].values\n",
    "\n",
    "# 计算 macro-AUC\n",
    "macro_auc = roc_auc_score(y_true, y_pred, average=\"macro\", multi_class=\"ovr\")\n",
    "print(\"Macro-AUC:\", macro_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5874de-7339-4e43-b6e3-fc4f93f5cf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
