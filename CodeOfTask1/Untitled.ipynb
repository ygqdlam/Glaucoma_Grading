{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e15e997-d8e0-4d97-86a9-2c1b9df37da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nums: 100, train: 80, val: 20\n",
      "['0053', '0051', '0074', '0008', '0086', '0013', '0084', '0097', '0014', '0002', '0058', '0033', '0069', '0052', '0005', '0077', '0075', '0061', '0045', '0098']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # 让报错指向真实算子\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.vision.models import resnet34, resnet50\n",
    "\n",
    "import transforms as trans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "paddle.set_device('gpu' if paddle.device.is_compiled_with_cuda() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "batchsize = 4 # 4 patients per iter, i.e, 20 steps / epoch\n",
    "oct_img_size = [512, 512]\n",
    "image_size = 256\n",
    "iters = 1000 # For demonstration purposes only, far from reaching convergence\n",
    "val_ratio = 0.2 # 80 / 20\n",
    "trainset_root = \"/home/yanggq/project/grading/Glaucoma_grading/training/multi-modality_images\"\n",
    "# test_root = \"\"\n",
    "num_workers = 4\n",
    "init_lr = 1e-4\n",
    "optimizer_type = \"adam\"\n",
    "\n",
    "\n",
    "filelists = os.listdir(trainset_root)\n",
    "train_filelists, val_filelists = train_test_split(filelists, test_size=val_ratio, random_state=12)\n",
    "print(\"Total Nums: {}, train: {}, val: {}\".format(len(filelists), len(train_filelists), len(val_filelists)))\n",
    "print(val_filelists)\n",
    "\n",
    "\n",
    "\n",
    "class GAMMA_sub1_dataset(paddle.io.Dataset):\n",
    "    \"\"\"\n",
    "    getitem() output:\n",
    "    \n",
    "    \tfundus_img: RGB uint8 image with shape (3, image_size, image_size)\n",
    "        \n",
    "        oct_img:    Uint8 image with shape (256, oct_img_size[0], oct_img_size[1])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 img_transforms,\n",
    "                 oct_transforms,\n",
    "                 dataset_root,\n",
    "                 label_file='',\n",
    "                 filelists=None,\n",
    "                 num_classes=3,\n",
    "                 mode='train'):\n",
    "\n",
    "        self.dataset_root = dataset_root\n",
    "        self.img_transforms = img_transforms\n",
    "        self.oct_transforms = oct_transforms\n",
    "        self.mode = mode.lower()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            label = {row['data']: row[1:].values \n",
    "                        for _, row in pd.read_excel(label_file).iterrows()}\n",
    "\n",
    "            self.file_list = [[f, label[int(f)]] for f in os.listdir(dataset_root)]\n",
    "        elif self.mode == \"test\":\n",
    "            self.file_list = [[f, None] for f in os.listdir(dataset_root)]\n",
    "        \n",
    "        if filelists is not None:\n",
    "            self.file_list = [item for item in self.file_list if item[0] in filelists]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_index, label = self.file_list[idx]\n",
    "        #print(\"1111\",label)\n",
    "        fundus_img_path = os.path.join(self.dataset_root, real_index, real_index + \".jpg\")\n",
    "        oct_series_list = sorted(os.listdir(os.path.join(self.dataset_root, real_index, real_index)), \n",
    "                                    key=lambda x: int(x.strip(\"_\")[0]))\n",
    "\n",
    "        fundus_img = cv2.imread(fundus_img_path)[:, :, ::-1] # BGR -> RGB\n",
    "        oct_series_0 = cv2.imread(os.path.join(self.dataset_root, real_index, real_index, oct_series_list[0]), \n",
    "                                    cv2.IMREAD_GRAYSCALE)\n",
    "        oct_img = np.zeros((len(oct_series_list), oct_series_0.shape[0], oct_series_0.shape[1], 1), dtype=\"uint8\")\n",
    "\n",
    "        for k, p in enumerate(oct_series_list):\n",
    "            oct_img[k] = cv2.imread(\n",
    "                os.path.join(self.dataset_root, real_index, real_index, p), cv2.IMREAD_GRAYSCALE)[..., np.newaxis]\n",
    "\n",
    "        if self.img_transforms is not None:\n",
    "            fundus_img = self.img_transforms(fundus_img)\n",
    "        if self.oct_transforms is not None:\n",
    "            oct_img = self.oct_transforms(oct_img)\n",
    " \n",
    "        # normlize on GPU to save CPU Memory and IO consuming.\n",
    "        # fundus_img = (fundus_img / 255.).astype(\"float32\")\n",
    "        # oct_img = (oct_img / 255.).astype(\"float32\")\n",
    "\n",
    "        fundus_img = fundus_img.transpose(2, 0, 1) # H, W, C -> C, H, W\n",
    "        oct_img = oct_img.squeeze(-1) # D, H, W, 1 -> D, H, W\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return fundus_img, oct_img, real_index\n",
    "        if self.mode == \"train\":\n",
    "            class_id = np.int64(np.argmax(label))     # ← 只这一行就够\n",
    "            return fundus_img, oct_img, class_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "\n",
    "img_train_transforms = trans.Compose([\n",
    "    trans.RandomResizedCrop(\n",
    "        image_size, scale=(0.90, 1.1), ratio=(0.90, 1.1)),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "    trans.RandomRotation(30)\n",
    "])\n",
    "\n",
    "oct_train_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "img_val_transforms = trans.Compose([\n",
    "    trans.CropCenterSquare(),\n",
    "    trans.Resize((image_size, image_size))\n",
    "])\n",
    "\n",
    "oct_val_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size)\n",
    "])\n",
    "\n",
    "\n",
    "_train = GAMMA_sub1_dataset(dataset_root=trainset_root, \n",
    "                        img_transforms=img_train_transforms,\n",
    "                        oct_transforms=oct_train_transforms,\n",
    "                        label_file='/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx')\n",
    "\n",
    "_val = GAMMA_sub1_dataset(dataset_root=trainset_root, \n",
    "                        img_transforms=img_val_transforms,\n",
    "                        oct_transforms=oct_val_transforms,\n",
    "                        label_file='/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx')\n",
    "\n",
    "\n",
    "class Model(nn.Layer):\n",
    "    \"\"\"\n",
    "    simply create a 2-branch network, and concat global pooled feature vector.\n",
    "    each branch = single resnet34\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fundus_branch = resnet34(pretrained=True, num_classes=0) # remove final fc\n",
    "        self.oct_branch = resnet34(pretrained=True, num_classes=0) # remove final fc\n",
    "        self.decision_branch = nn.Linear(512 * 1 * 2, 3) # ResNet34 use basic block, expansion = 1\n",
    "        \n",
    "        # replace first conv layer in oct_branch\n",
    "        self.oct_branch.conv1 = nn.Conv2D(256, 64,\n",
    "                                        kernel_size=7,\n",
    "                                        stride=2,\n",
    "                                        padding=3,\n",
    "                                        bias_attr=False)\n",
    "\n",
    "    def forward(self, fundus_img, oct_img):\n",
    "        b1 = self.fundus_branch(fundus_img)\n",
    "        b2 = self.oct_branch(oct_img)\n",
    "        b1 = paddle.flatten(b1, 1)\n",
    "        b2 = paddle.flatten(b2, 1)\n",
    "        logit = self.decision_branch(paddle.concat([b1, b2], 1))\n",
    "\n",
    "        return logit\n",
    "\n",
    "class Model_resnet50(nn.Layer):\n",
    "    \"\"\"\n",
    "    simply create a 2-branch network, and concat global pooled feature vector.\n",
    "    each branch = single resnet34\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Model_resnet50, self).__init__()\n",
    "        self.fundus_branch = resnet50(pretrained=True, num_classes=0) # remove final fc\n",
    "        self.oct_branch = resnet50(pretrained=True, num_classes=0) # remove final fc\n",
    "        self.decision_branch = nn.Linear(512 * 4 * 2, 3) # ResNet34 use bottleneck block, expansion = 4\n",
    "        \n",
    "        # replace first conv layer in oct_branch\n",
    "        self.oct_branch.conv1 = nn.Conv2D(256, 64,\n",
    "                                        kernel_size=7,\n",
    "                                        stride=2,\n",
    "                                        padding=3,\n",
    "                                        bias_attr=False)\n",
    "\n",
    "    def forward(self, fundus_img, oct_img):\n",
    "        b1 = self.fundus_branch(fundus_img)\n",
    "        b2 = self.oct_branch(oct_img)\n",
    "        b1 = paddle.flatten(b1, 1)\n",
    "        b2 = paddle.flatten(b2, 1)\n",
    "        logit = self.decision_branch(paddle.concat([b1, b2], 1))\n",
    "\n",
    "        return logit\n",
    "\n",
    "img_train_transforms = trans.Compose([\n",
    "    trans.RandomResizedCrop(\n",
    "        image_size, scale=(0.90, 1.1), ratio=(0.90, 1.1)),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "    trans.RandomRotation(30)\n",
    "])\n",
    "\n",
    "oct_train_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "img_val_transforms = trans.Compose([\n",
    "    trans.CropCenterSquare(),\n",
    "    trans.Resize((image_size, image_size))\n",
    "])\n",
    "\n",
    "oct_val_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size)\n",
    "])\n",
    "\n",
    "train_dataset = GAMMA_sub1_dataset(dataset_root=trainset_root, \n",
    "                        img_transforms=img_train_transforms,\n",
    "                        oct_transforms=oct_train_transforms,\n",
    "                        filelists=train_filelists,\n",
    "                        label_file='/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx')\n",
    "\n",
    "val_dataset = GAMMA_sub1_dataset(dataset_root=trainset_root, \n",
    "                        img_transforms=img_val_transforms,\n",
    "                        oct_transforms=oct_val_transforms,\n",
    "                        filelists=val_filelists,\n",
    "                        label_file='/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def my_collate(batch):\n",
    "    # batch: [(fundus, oct, class_id), ...]\n",
    "    f_list, o_list, y_list = zip(*batch)\n",
    "    f = np.stack(f_list, axis=0).astype('uint8')     # [N, 3, H, W]\n",
    "    o = np.stack(o_list, axis=0).astype('uint8')     # [N, D, H, W]\n",
    "    y = np.asarray(y_list, dtype=np.int64)           # [N] int64（0..C-1）\n",
    "    return f, o, y\n",
    "\n",
    "#train_loader = paddle.io.DataLoader(\n",
    "#    train_dataset,\n",
    "#    batch_sampler=paddle.io.DistributedBatchSampler(train_dataset, batch_size=batchsize, shuffle=True, drop_last=False),\n",
    "#    num_workers=num_workers,\n",
    "#    collate_fn=my_collate,        # ← 新增\n",
    "#    return_list=True,\n",
    "#    use_shared_memory=False\n",
    "#)\n",
    "\n",
    "val_loader = paddle.io.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(val_dataset, batch_size=batchsize, shuffle=True, drop_last=False),\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=my_collate,        # ← 新增\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")\n",
    "\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchsize, shuffle=True,\n",
    "    num_workers=0,                   # ← 调试先关\n",
    "    collate_fn=my_collate,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")\n",
    "\n",
    "\n",
    "model = Model()\n",
    "\n",
    "if optimizer_type == \"adam\":\n",
    "    optimizer = paddle.optimizer.Adam(init_lr, parameters=model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "def train(model, iters, train_dataloader, val_dataloader, optimizer, criterion, log_interval, eval_interval):\n",
    "    iter = 0\n",
    "    model.train()\n",
    "    avg_loss_list = []\n",
    "    avg_kappa_list = []\n",
    "    best_kappa = 0.\n",
    "    while iter < iters:\n",
    "        for data in train_dataloader:\n",
    "            iter += 1\n",
    "            if iter > iters:\n",
    "                break\n",
    "            #fundus_imgs = (data[0] / 255.).astype(\"float32\")\n",
    "            #oct_imgs = (data[1] / 255.).astype(\"float32\")\n",
    "            #labels = data[2].astype('int64')\n",
    "            fundus_imgs = paddle.to_tensor(data[0].astype('float32') / 255.0)\n",
    "            oct_imgs    = paddle.to_tensor(data[1].astype('float32') / 255.0)\n",
    "            labels      = paddle.to_tensor(data[2], dtype='int64')    # [N]\n",
    "\n",
    "            logits = model(fundus_imgs, oct_imgs)\n",
    "            \n",
    "            N, C = logits.shape\n",
    "\n",
    "            lb_min = int(labels.min().item()); lb_max = int(labels.max().item())\n",
    "            assert 0 <= lb_min and lb_max < C, f\"label out of range [{lb_min},{lb_max}] vs C={C}\"\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            # acc = paddle.metric.accuracy(input=logits, label=labels.reshape((-1, 1)), k=1)\n",
    "            for p, l in zip(logits.numpy().argmax(1), labels.numpy()):\n",
    "                avg_kappa_list.append([p, l])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.clear_gradients()\n",
    "            #avg_loss_list.append(loss.numpy()[0])\n",
    "            avg_loss_list.append(loss.numpy().item())   # 推荐：numpy 标量 -> Python float\n",
    "\n",
    "            if iter % log_interval == 0:\n",
    "                avg_loss = np.array(avg_loss_list).mean()\n",
    "                avg_kappa_list = np.array(avg_kappa_list)\n",
    "                avg_kappa = cohen_kappa_score(avg_kappa_list[:, 0], avg_kappa_list[:, 1], weights='quadratic')\n",
    "                avg_loss_list = []\n",
    "                avg_kappa_list = []\n",
    "                print(\"[TRAIN] iter={}/{} avg_loss={:.4f} avg_kappa={:.4f}\".format(iter, iters, avg_loss, avg_kappa))\n",
    "\n",
    "            if iter % eval_interval == 0:\n",
    "                avg_loss, avg_kappa = val(model, val_dataloader, criterion)\n",
    "                print(\"[EVAL] iter={}/{} avg_loss={:.4f} kappa={:.4f}\".format(iter, iters, avg_loss, avg_kappa))\n",
    "                if avg_kappa >= best_kappa:\n",
    "                    best_kappa = avg_kappa\n",
    "                    paddle.save(model.state_dict(),\n",
    "                            os.path.join('trained_models', \"best_model_{:.4f}\".format(best_kappa), 'model.pdparams'))\n",
    "                    paddle.save(optimizer.state_dict(), \n",
    "                            os.path.join('trained_models',\"best_model_{:.4f}\".format(best_kappa), 'optimizer.pdopt'))\n",
    "                model.train()\n",
    "\n",
    "def val(model, val_dataloader, criterion):\n",
    "    model.eval()\n",
    "    avg_loss_list = []\n",
    "    cache = []\n",
    "    with paddle.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            fundus_imgs = (data[0] / 255.).astype(\"float32\")\n",
    "            oct_imgs = (data[1] / 255.).astype(\"float32\")\n",
    "            labels = data[2].astype('int64')\n",
    "            \n",
    "            logits = model(fundus_imgs, oct_imgs)\n",
    "            for p, l in zip(logits.numpy().argmax(1), labels.numpy()):\n",
    "                cache.append([p, l])\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            # acc = paddle.metric.accuracy(input=logits, label=labels.reshape((-1, 1)), k=1)\n",
    "            #avg_loss_list.append(loss.numpy()[0])\n",
    "            avg_loss_list.append(loss.numpy().item())   # 推荐：numpy 标量 -> Python float\n",
    "    cache = np.array(cache)\n",
    "    kappa = cohen_kappa_score(cache[:, 0], cache[:, 1], weights='quadratic')\n",
    "    avg_loss = np.array(avg_loss_list).mean()\n",
    "\n",
    "    return avg_loss, kappa\n",
    "\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e2a6ae0-dc6c-40c5-8fce-d45b8cb8a557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels dtype: paddle.int64 shape: [4]\n",
      "labels: Tensor(shape=[4], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [-5969391045393843441,  5490832532120929525, -3483077381177840028,\n",
      "         3867235770383922429]) min/max: Tensor(shape=[], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       -5969391045393843441) Tensor(shape=[], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       5490832532120929525)\n"
     ]
    }
   ],
   "source": [
    "fundus, octv, labels = next(train_loader())\n",
    "print(\"labels dtype:\", labels.dtype, \"shape:\", labels.shape)\n",
    "print(\"labels:\", labels, \"min/max:\", labels.min(), labels.max())\n",
    "# 期望: dtype=int64, shape=(N,), 值在 [0, C-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d990791-33cf-436b-a91f-5946e72fdd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: [4, 3, 256, 256]\n",
      "labels: Tensor(shape=[4], dtype=int64, place=Place(gpu_pinned), stop_gradient=True,\n",
      "       [6070368908930537297, 5852507242796048697, 6073477061133089871,\n",
      "        7088501330633576278])\n",
      "labels dtype: paddle.int64\n",
      "labels unique: Tensor(shape=[4], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [5852507242796048697, 6070368908930537297, 6073477061133089871,\n",
      "        7088501330633576278])\n",
      "44444 Tensor(shape=[4], dtype=int64, place=Place(gpu_pinned), stop_gradient=True,\n",
      "       [4639078522492309830, 5355724829720592459, 4411360803608608328,\n",
      "        4846248369632982611])\n",
      "555555555 Tensor(shape=[4], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [4639078522492309830, 5355724829720592459, 4411360803608608328,\n",
      "        4846248369632982611])\n",
      "[debug] N=4, C=3, label_min=4411360803608608328, label_max=5355724829720592459\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "label out of range: min=4411360803608608328, max=5355724829720592459, num_classes=3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 344\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iters, train_dataloader, val_dataloader, optimizer, criterion, log_interval, eval_interval)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[debug] N=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, C=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, label_min=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlb_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, label_max=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlb_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lb_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m lb_max \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m C:\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel out of range: min=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlb_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, max=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlb_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_classes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# （若你的数据确实含无效标签，比如 -1/255，则用 ignore_index，并预处理成该值）\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# criterion = paddle.nn.CrossEntropyLoss(ignore_index=-1)\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# labels = paddle.where((labels < 0) | (labels >= C), paddle.to_tensor([-1], dtype='int64')[0], labels)\u001b[39;00m\n\u001b[1;32m    350\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, labels)\n",
      "\u001b[0;31mValueError\u001b[0m: label out of range: min=4411360803608608328, max=5355724829720592459, num_classes=3"
     ]
    }
   ],
   "source": [
    "train(model, iters, train_loader, val_loader, optimizer, criterion, log_interval=10, eval_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0eb5e6-151b-4268-925a-a3c5e71fbf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
