{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ec284a-b069-4650-85af-2635a5299d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Total Nums: 100, train: 80, val: 20\n",
      "labels sample: [1 1 2 2] dtype: int64 shape: (4,)\n",
      "[TRAIN] iter=10/10000 avg_loss=0.8657 avg_kappa=0.3056\n",
      "[TRAIN] iter=20/10000 avg_loss=0.8393 avg_kappa=0.5690\n",
      "[TRAIN] iter=30/10000 avg_loss=0.6135 avg_kappa=0.6937\n",
      "[TRAIN] iter=40/10000 avg_loss=0.7508 avg_kappa=0.6881\n",
      "[TRAIN] iter=50/10000 avg_loss=0.5900 avg_kappa=0.6784\n",
      "[TRAIN] iter=60/10000 avg_loss=0.5306 avg_kappa=0.7363\n",
      "[TRAIN] iter=70/10000 avg_loss=0.5428 avg_kappa=0.7674\n",
      "[TRAIN] iter=80/10000 avg_loss=0.3897 avg_kappa=0.7684\n",
      "[TRAIN] iter=90/10000 avg_loss=0.7558 avg_kappa=0.6840\n",
      "[TRAIN] iter=100/10000 avg_loss=0.4271 avg_kappa=0.7998\n",
      "[EVAL ] iter=100/10000 avg_loss=0.5818 kappa=0.5769\n",
      "[SAVE ] trained_models_torch/best_model_0.5769\n",
      "[TRAIN] iter=110/10000 avg_loss=0.4256 avg_kappa=0.8656\n",
      "[TRAIN] iter=120/10000 avg_loss=0.4548 avg_kappa=0.7710\n",
      "[TRAIN] iter=130/10000 avg_loss=0.3941 avg_kappa=0.7739\n",
      "[TRAIN] iter=140/10000 avg_loss=0.5128 avg_kappa=0.6822\n",
      "[TRAIN] iter=150/10000 avg_loss=0.2457 avg_kappa=0.9246\n",
      "[TRAIN] iter=160/10000 avg_loss=0.5611 avg_kappa=0.7446\n",
      "[TRAIN] iter=170/10000 avg_loss=0.2569 avg_kappa=0.9450\n",
      "[TRAIN] iter=180/10000 avg_loss=0.3829 avg_kappa=0.8263\n",
      "[TRAIN] iter=190/10000 avg_loss=0.3040 avg_kappa=0.8025\n",
      "[TRAIN] iter=200/10000 avg_loss=0.3826 avg_kappa=0.8214\n",
      "[EVAL ] iter=200/10000 avg_loss=0.9774 kappa=0.7283\n",
      "[SAVE ] trained_models_torch/best_model_0.7283\n",
      "[TRAIN] iter=210/10000 avg_loss=0.5174 avg_kappa=0.7674\n",
      "[TRAIN] iter=220/10000 avg_loss=0.5611 avg_kappa=0.8752\n",
      "[TRAIN] iter=230/10000 avg_loss=0.4200 avg_kappa=0.7518\n",
      "[TRAIN] iter=240/10000 avg_loss=0.4326 avg_kappa=0.7746\n",
      "[TRAIN] iter=250/10000 avg_loss=0.2122 avg_kappa=0.9144\n",
      "[TRAIN] iter=260/10000 avg_loss=0.3586 avg_kappa=0.8160\n",
      "[TRAIN] iter=270/10000 avg_loss=0.4966 avg_kappa=0.7923\n",
      "[TRAIN] iter=280/10000 avg_loss=0.2563 avg_kappa=0.9477\n",
      "[TRAIN] iter=290/10000 avg_loss=0.2172 avg_kappa=0.9115\n",
      "[TRAIN] iter=300/10000 avg_loss=0.4268 avg_kappa=0.7234\n",
      "[EVAL ] iter=300/10000 avg_loss=0.8160 kappa=0.6911\n",
      "[TRAIN] iter=310/10000 avg_loss=0.7580 avg_kappa=0.6620\n",
      "[TRAIN] iter=320/10000 avg_loss=0.4280 avg_kappa=0.6565\n",
      "[TRAIN] iter=330/10000 avg_loss=0.2494 avg_kappa=0.9310\n",
      "[TRAIN] iter=340/10000 avg_loss=0.3415 avg_kappa=0.8400\n",
      "[TRAIN] iter=350/10000 avg_loss=0.1069 avg_kappa=1.0000\n",
      "[TRAIN] iter=360/10000 avg_loss=0.2362 avg_kappa=0.9496\n",
      "[TRAIN] iter=370/10000 avg_loss=0.2532 avg_kappa=0.9458\n",
      "[TRAIN] iter=380/10000 avg_loss=0.5053 avg_kappa=0.6514\n",
      "[TRAIN] iter=390/10000 avg_loss=0.3505 avg_kappa=0.8806\n",
      "[TRAIN] iter=400/10000 avg_loss=0.7452 avg_kappa=0.7710\n",
      "[EVAL ] iter=400/10000 avg_loss=0.7801 kappa=0.6739\n",
      "[TRAIN] iter=410/10000 avg_loss=0.1831 avg_kappa=0.8905\n",
      "[TRAIN] iter=420/10000 avg_loss=0.2730 avg_kappa=0.8523\n",
      "[TRAIN] iter=430/10000 avg_loss=0.1494 avg_kappa=0.9065\n",
      "[TRAIN] iter=440/10000 avg_loss=0.3366 avg_kappa=0.9089\n",
      "[TRAIN] iter=450/10000 avg_loss=0.3522 avg_kappa=0.8367\n",
      "[TRAIN] iter=460/10000 avg_loss=0.2262 avg_kappa=0.8908\n",
      "[TRAIN] iter=470/10000 avg_loss=0.1745 avg_kappa=0.9615\n",
      "[TRAIN] iter=480/10000 avg_loss=0.1141 avg_kappa=0.9822\n",
      "[TRAIN] iter=490/10000 avg_loss=0.1786 avg_kappa=0.9585\n",
      "[TRAIN] iter=500/10000 avg_loss=0.1911 avg_kappa=0.8208\n",
      "[EVAL ] iter=500/10000 avg_loss=0.6855 kappa=0.6413\n",
      "[TRAIN] iter=510/10000 avg_loss=0.0924 avg_kappa=1.0000\n",
      "[TRAIN] iter=520/10000 avg_loss=0.1255 avg_kappa=0.9579\n",
      "[TRAIN] iter=530/10000 avg_loss=0.1744 avg_kappa=0.8837\n",
      "[TRAIN] iter=540/10000 avg_loss=0.2704 avg_kappa=0.9427\n",
      "[TRAIN] iter=550/10000 avg_loss=0.2531 avg_kappa=0.8288\n",
      "[TRAIN] iter=560/10000 avg_loss=0.2000 avg_kappa=0.8894\n",
      "[TRAIN] iter=570/10000 avg_loss=0.2208 avg_kappa=0.9254\n",
      "[TRAIN] iter=580/10000 avg_loss=0.3410 avg_kappa=0.8884\n",
      "[TRAIN] iter=590/10000 avg_loss=0.3853 avg_kappa=0.6564\n",
      "[TRAIN] iter=600/10000 avg_loss=0.2291 avg_kappa=0.9064\n",
      "[EVAL ] iter=600/10000 avg_loss=1.1771 kappa=0.3627\n",
      "[TRAIN] iter=610/10000 avg_loss=0.1111 avg_kappa=0.9775\n",
      "[TRAIN] iter=620/10000 avg_loss=0.2509 avg_kappa=0.8391\n",
      "[TRAIN] iter=630/10000 avg_loss=0.2843 avg_kappa=0.8512\n",
      "[TRAIN] iter=640/10000 avg_loss=0.2395 avg_kappa=0.7951\n",
      "[TRAIN] iter=650/10000 avg_loss=0.3319 avg_kappa=0.9243\n",
      "[TRAIN] iter=660/10000 avg_loss=0.1766 avg_kappa=0.9286\n",
      "[TRAIN] iter=670/10000 avg_loss=0.2929 avg_kappa=0.9149\n",
      "[TRAIN] iter=680/10000 avg_loss=0.2673 avg_kappa=0.9160\n",
      "[TRAIN] iter=690/10000 avg_loss=0.1917 avg_kappa=0.8814\n",
      "[TRAIN] iter=700/10000 avg_loss=0.2361 avg_kappa=0.9057\n",
      "[EVAL ] iter=700/10000 avg_loss=0.9789 kappa=0.6250\n",
      "[TRAIN] iter=710/10000 avg_loss=0.1100 avg_kappa=0.9836\n",
      "[TRAIN] iter=720/10000 avg_loss=0.2791 avg_kappa=0.8216\n",
      "[TRAIN] iter=730/10000 avg_loss=0.0851 avg_kappa=0.8491\n",
      "[TRAIN] iter=740/10000 avg_loss=0.3890 avg_kappa=0.9071\n",
      "[TRAIN] iter=750/10000 avg_loss=0.2091 avg_kappa=0.9444\n",
      "[TRAIN] iter=760/10000 avg_loss=0.5336 avg_kappa=0.6154\n",
      "[TRAIN] iter=770/10000 avg_loss=0.0554 avg_kappa=1.0000\n",
      "[TRAIN] iter=780/10000 avg_loss=0.1459 avg_kappa=0.9370\n",
      "[TRAIN] iter=790/10000 avg_loss=0.1133 avg_kappa=0.8819\n",
      "[TRAIN] iter=800/10000 avg_loss=0.1422 avg_kappa=0.7812\n",
      "[EVAL ] iter=800/10000 avg_loss=0.6704 kappa=0.6043\n",
      "[TRAIN] iter=810/10000 avg_loss=0.3277 avg_kappa=0.7552\n",
      "[TRAIN] iter=820/10000 avg_loss=0.2531 avg_kappa=0.8006\n",
      "[TRAIN] iter=830/10000 avg_loss=0.1076 avg_kappa=1.0000\n",
      "[TRAIN] iter=840/10000 avg_loss=0.0723 avg_kappa=0.9775\n",
      "[TRAIN] iter=850/10000 avg_loss=0.1855 avg_kappa=0.8280\n",
      "[TRAIN] iter=860/10000 avg_loss=0.1736 avg_kappa=0.9411\n",
      "[TRAIN] iter=870/10000 avg_loss=0.0998 avg_kappa=1.0000\n",
      "[TRAIN] iter=880/10000 avg_loss=0.0638 avg_kappa=0.9823\n",
      "[TRAIN] iter=890/10000 avg_loss=0.0364 avg_kappa=1.0000\n",
      "[TRAIN] iter=900/10000 avg_loss=0.1765 avg_kappa=0.8906\n",
      "[EVAL ] iter=900/10000 avg_loss=0.7704 kappa=0.8750\n",
      "[SAVE ] trained_models_torch/best_model_0.8750\n",
      "[TRAIN] iter=910/10000 avg_loss=0.1343 avg_kappa=0.9289\n",
      "[TRAIN] iter=920/10000 avg_loss=0.1310 avg_kappa=0.8967\n",
      "[TRAIN] iter=930/10000 avg_loss=0.0494 avg_kappa=0.9808\n",
      "[TRAIN] iter=940/10000 avg_loss=0.1110 avg_kappa=0.9271\n",
      "[TRAIN] iter=950/10000 avg_loss=0.0409 avg_kappa=1.0000\n",
      "[TRAIN] iter=960/10000 avg_loss=0.0533 avg_kappa=0.9807\n",
      "[TRAIN] iter=970/10000 avg_loss=0.0411 avg_kappa=1.0000\n",
      "[TRAIN] iter=980/10000 avg_loss=0.0196 avg_kappa=1.0000\n",
      "[TRAIN] iter=990/10000 avg_loss=0.0260 avg_kappa=1.0000\n",
      "[TRAIN] iter=1000/10000 avg_loss=0.0288 avg_kappa=1.0000\n",
      "[EVAL ] iter=1000/10000 avg_loss=0.7203 kappa=0.7482\n",
      "[TRAIN] iter=1010/10000 avg_loss=0.0548 avg_kappa=1.0000\n",
      "[TRAIN] iter=1020/10000 avg_loss=0.2930 avg_kappa=0.8171\n",
      "[TRAIN] iter=1030/10000 avg_loss=0.0156 avg_kappa=1.0000\n",
      "[TRAIN] iter=1040/10000 avg_loss=0.0624 avg_kappa=0.9823\n",
      "[TRAIN] iter=1050/10000 avg_loss=0.1126 avg_kappa=0.9813\n",
      "[TRAIN] iter=1060/10000 avg_loss=0.1768 avg_kappa=0.8894\n",
      "[TRAIN] iter=1070/10000 avg_loss=0.0404 avg_kappa=1.0000\n",
      "[TRAIN] iter=1080/10000 avg_loss=0.0628 avg_kappa=0.9306\n",
      "[TRAIN] iter=1090/10000 avg_loss=0.3629 avg_kappa=0.8826\n",
      "[TRAIN] iter=1100/10000 avg_loss=0.0996 avg_kappa=0.9769\n",
      "[EVAL ] iter=1100/10000 avg_loss=0.9464 kappa=0.5769\n",
      "[TRAIN] iter=1110/10000 avg_loss=0.1786 avg_kappa=0.9249\n",
      "[TRAIN] iter=1120/10000 avg_loss=0.1441 avg_kappa=0.9796\n",
      "[TRAIN] iter=1130/10000 avg_loss=0.1579 avg_kappa=0.9782\n",
      "[TRAIN] iter=1140/10000 avg_loss=0.1938 avg_kappa=0.9139\n",
      "[TRAIN] iter=1150/10000 avg_loss=0.0252 avg_kappa=1.0000\n",
      "[TRAIN] iter=1160/10000 avg_loss=0.0545 avg_kappa=1.0000\n",
      "[TRAIN] iter=1170/10000 avg_loss=0.0225 avg_kappa=1.0000\n",
      "[TRAIN] iter=1180/10000 avg_loss=0.0244 avg_kappa=1.0000\n",
      "[TRAIN] iter=1190/10000 avg_loss=0.0663 avg_kappa=0.9833\n",
      "[TRAIN] iter=1200/10000 avg_loss=0.2462 avg_kappa=0.9200\n",
      "[EVAL ] iter=1200/10000 avg_loss=0.8061 kappa=0.5676\n",
      "[TRAIN] iter=1210/10000 avg_loss=0.0515 avg_kappa=0.9780\n",
      "[TRAIN] iter=1220/10000 avg_loss=0.0529 avg_kappa=1.0000\n",
      "[TRAIN] iter=1230/10000 avg_loss=0.1705 avg_kappa=0.8864\n",
      "[TRAIN] iter=1240/10000 avg_loss=0.1942 avg_kappa=0.9450\n",
      "[TRAIN] iter=1250/10000 avg_loss=0.2627 avg_kappa=0.8897\n",
      "[TRAIN] iter=1260/10000 avg_loss=0.2623 avg_kappa=0.8349\n",
      "[TRAIN] iter=1270/10000 avg_loss=0.2858 avg_kappa=0.9065\n",
      "[TRAIN] iter=1280/10000 avg_loss=0.0641 avg_kappa=1.0000\n",
      "[TRAIN] iter=1290/10000 avg_loss=0.0839 avg_kappa=0.9621\n",
      "[TRAIN] iter=1300/10000 avg_loss=0.0694 avg_kappa=0.9806\n",
      "[EVAL ] iter=1300/10000 avg_loss=0.6075 kappa=0.8340\n",
      "[TRAIN] iter=1310/10000 avg_loss=0.0594 avg_kappa=1.0000\n",
      "[TRAIN] iter=1320/10000 avg_loss=0.0273 avg_kappa=1.0000\n",
      "[TRAIN] iter=1330/10000 avg_loss=0.2207 avg_kappa=0.9242\n",
      "[TRAIN] iter=1340/10000 avg_loss=0.0878 avg_kappa=0.9813\n",
      "[TRAIN] iter=1350/10000 avg_loss=0.0561 avg_kappa=0.9815\n",
      "[TRAIN] iter=1360/10000 avg_loss=0.0461 avg_kappa=1.0000\n",
      "[TRAIN] iter=1370/10000 avg_loss=0.0506 avg_kappa=0.9794\n",
      "[TRAIN] iter=1380/10000 avg_loss=0.0514 avg_kappa=0.9817\n",
      "[TRAIN] iter=1390/10000 avg_loss=0.0145 avg_kappa=1.0000\n",
      "[TRAIN] iter=1400/10000 avg_loss=0.0307 avg_kappa=1.0000\n",
      "[EVAL ] iter=1400/10000 avg_loss=1.0994 kappa=0.5588\n",
      "[TRAIN] iter=1410/10000 avg_loss=0.0448 avg_kappa=1.0000\n",
      "[TRAIN] iter=1420/10000 avg_loss=0.0173 avg_kappa=1.0000\n",
      "[TRAIN] iter=1430/10000 avg_loss=0.0200 avg_kappa=1.0000\n",
      "[TRAIN] iter=1440/10000 avg_loss=0.0503 avg_kappa=1.0000\n",
      "[TRAIN] iter=1450/10000 avg_loss=0.0734 avg_kappa=0.9823\n",
      "[TRAIN] iter=1460/10000 avg_loss=0.0528 avg_kappa=1.0000\n",
      "[TRAIN] iter=1470/10000 avg_loss=0.2547 avg_kappa=0.8384\n",
      "[TRAIN] iter=1480/10000 avg_loss=0.0268 avg_kappa=0.9798\n",
      "[TRAIN] iter=1490/10000 avg_loss=0.0536 avg_kappa=1.0000\n",
      "[TRAIN] iter=1500/10000 avg_loss=0.1432 avg_kappa=0.9652\n",
      "[EVAL ] iter=1500/10000 avg_loss=1.0320 kappa=0.7285\n",
      "[TRAIN] iter=1510/10000 avg_loss=0.0424 avg_kappa=1.0000\n",
      "[TRAIN] iter=1520/10000 avg_loss=0.0193 avg_kappa=1.0000\n",
      "[TRAIN] iter=1530/10000 avg_loss=0.0251 avg_kappa=1.0000\n",
      "[TRAIN] iter=1540/10000 avg_loss=0.2232 avg_kappa=0.9643\n",
      "[TRAIN] iter=1550/10000 avg_loss=0.2482 avg_kappa=0.9368\n",
      "[TRAIN] iter=1560/10000 avg_loss=0.0449 avg_kappa=1.0000\n",
      "[TRAIN] iter=1570/10000 avg_loss=0.1344 avg_kappa=0.8824\n",
      "[TRAIN] iter=1580/10000 avg_loss=0.0312 avg_kappa=1.0000\n",
      "[TRAIN] iter=1590/10000 avg_loss=0.1298 avg_kappa=0.9065\n",
      "[TRAIN] iter=1600/10000 avg_loss=0.1366 avg_kappa=0.9815\n",
      "[EVAL ] iter=1600/10000 avg_loss=1.0268 kappa=0.6416\n",
      "[TRAIN] iter=1610/10000 avg_loss=0.1019 avg_kappa=0.9640\n",
      "[TRAIN] iter=1620/10000 avg_loss=0.0526 avg_kappa=0.9810\n",
      "[TRAIN] iter=1630/10000 avg_loss=0.2173 avg_kappa=0.9630\n",
      "[TRAIN] iter=1640/10000 avg_loss=0.0595 avg_kappa=0.9789\n",
      "[TRAIN] iter=1650/10000 avg_loss=0.1521 avg_kappa=0.9789\n",
      "[TRAIN] iter=1660/10000 avg_loss=0.0522 avg_kappa=1.0000\n",
      "[TRAIN] iter=1670/10000 avg_loss=0.0262 avg_kappa=1.0000\n",
      "[TRAIN] iter=1680/10000 avg_loss=0.0243 avg_kappa=1.0000\n",
      "[TRAIN] iter=1690/10000 avg_loss=0.0235 avg_kappa=1.0000\n",
      "[TRAIN] iter=1700/10000 avg_loss=0.1313 avg_kappa=0.9817\n",
      "[EVAL ] iter=1700/10000 avg_loss=0.5935 kappa=0.6416\n",
      "[TRAIN] iter=1710/10000 avg_loss=0.0831 avg_kappa=0.9834\n",
      "[TRAIN] iter=1720/10000 avg_loss=0.1108 avg_kappa=0.9772\n",
      "[TRAIN] iter=1730/10000 avg_loss=0.1683 avg_kappa=0.9635\n",
      "[TRAIN] iter=1740/10000 avg_loss=0.0301 avg_kappa=1.0000\n",
      "[TRAIN] iter=1750/10000 avg_loss=0.0135 avg_kappa=1.0000\n",
      "[TRAIN] iter=1760/10000 avg_loss=0.0962 avg_kappa=0.9656\n",
      "[TRAIN] iter=1770/10000 avg_loss=0.0597 avg_kappa=0.9805\n",
      "[TRAIN] iter=1780/10000 avg_loss=0.0188 avg_kappa=1.0000\n",
      "[TRAIN] iter=1790/10000 avg_loss=0.0265 avg_kappa=1.0000\n",
      "[TRAIN] iter=1800/10000 avg_loss=0.0141 avg_kappa=1.0000\n",
      "[EVAL ] iter=1800/10000 avg_loss=0.5915 kappa=0.7287\n",
      "[TRAIN] iter=1810/10000 avg_loss=0.0239 avg_kappa=1.0000\n",
      "[TRAIN] iter=1820/10000 avg_loss=0.0169 avg_kappa=1.0000\n",
      "[TRAIN] iter=1830/10000 avg_loss=0.0079 avg_kappa=1.0000\n",
      "[TRAIN] iter=1840/10000 avg_loss=0.0222 avg_kappa=1.0000\n",
      "[TRAIN] iter=1850/10000 avg_loss=0.0261 avg_kappa=1.0000\n",
      "[TRAIN] iter=1860/10000 avg_loss=0.0181 avg_kappa=1.0000\n",
      "[TRAIN] iter=1870/10000 avg_loss=0.0141 avg_kappa=1.0000\n",
      "[TRAIN] iter=1880/10000 avg_loss=0.0073 avg_kappa=1.0000\n",
      "[TRAIN] iter=1890/10000 avg_loss=0.0100 avg_kappa=1.0000\n",
      "[TRAIN] iter=1900/10000 avg_loss=0.0027 avg_kappa=1.0000\n",
      "[EVAL ] iter=1900/10000 avg_loss=0.6899 kappa=0.7510\n",
      "[TRAIN] iter=1910/10000 avg_loss=0.0568 avg_kappa=1.0000\n",
      "[TRAIN] iter=1920/10000 avg_loss=0.0107 avg_kappa=1.0000\n",
      "[TRAIN] iter=1930/10000 avg_loss=0.0048 avg_kappa=1.0000\n",
      "[TRAIN] iter=1940/10000 avg_loss=0.1896 avg_kappa=0.9749\n",
      "[TRAIN] iter=1950/10000 avg_loss=0.0254 avg_kappa=1.0000\n",
      "[TRAIN] iter=1960/10000 avg_loss=0.1074 avg_kappa=0.9825\n",
      "[TRAIN] iter=1970/10000 avg_loss=0.0154 avg_kappa=1.0000\n",
      "[TRAIN] iter=1980/10000 avg_loss=0.0219 avg_kappa=1.0000\n",
      "[TRAIN] iter=1990/10000 avg_loss=0.0255 avg_kappa=1.0000\n",
      "[TRAIN] iter=2000/10000 avg_loss=0.1725 avg_kappa=0.9671\n",
      "[EVAL ] iter=2000/10000 avg_loss=0.6053 kappa=0.6939\n",
      "[TRAIN] iter=2010/10000 avg_loss=0.0232 avg_kappa=1.0000\n",
      "[TRAIN] iter=2020/10000 avg_loss=0.0532 avg_kappa=0.9841\n",
      "[TRAIN] iter=2030/10000 avg_loss=0.0276 avg_kappa=1.0000\n",
      "[TRAIN] iter=2040/10000 avg_loss=0.0344 avg_kappa=1.0000\n",
      "[TRAIN] iter=2050/10000 avg_loss=0.0595 avg_kappa=0.9629\n",
      "[TRAIN] iter=2060/10000 avg_loss=0.2481 avg_kappa=0.9813\n",
      "[TRAIN] iter=2070/10000 avg_loss=0.0540 avg_kappa=0.9789\n",
      "[TRAIN] iter=2080/10000 avg_loss=0.0536 avg_kappa=0.9834\n",
      "[TRAIN] iter=2090/10000 avg_loss=0.0484 avg_kappa=0.9828\n",
      "[TRAIN] iter=2100/10000 avg_loss=0.0978 avg_kappa=0.9592\n",
      "[EVAL ] iter=2100/10000 avg_loss=0.8276 kappa=0.6911\n",
      "[TRAIN] iter=2110/10000 avg_loss=0.0285 avg_kappa=1.0000\n",
      "[TRAIN] iter=2120/10000 avg_loss=0.0546 avg_kappa=0.9820\n",
      "[TRAIN] iter=2130/10000 avg_loss=0.0114 avg_kappa=1.0000\n",
      "[TRAIN] iter=2140/10000 avg_loss=0.0983 avg_kappa=0.9621\n",
      "[TRAIN] iter=2150/10000 avg_loss=0.0475 avg_kappa=0.9782\n",
      "[TRAIN] iter=2160/10000 avg_loss=0.0415 avg_kappa=1.0000\n",
      "[TRAIN] iter=2170/10000 avg_loss=0.0311 avg_kappa=1.0000\n",
      "[TRAIN] iter=2180/10000 avg_loss=0.0086 avg_kappa=1.0000\n",
      "[TRAIN] iter=2190/10000 avg_loss=0.0088 avg_kappa=1.0000\n",
      "[TRAIN] iter=2200/10000 avg_loss=0.0535 avg_kappa=0.9270\n",
      "[EVAL ] iter=2200/10000 avg_loss=0.5648 kappa=0.6043\n",
      "[TRAIN] iter=2210/10000 avg_loss=0.0370 avg_kappa=1.0000\n",
      "[TRAIN] iter=2220/10000 avg_loss=0.0300 avg_kappa=1.0000\n",
      "[TRAIN] iter=2230/10000 avg_loss=0.0259 avg_kappa=1.0000\n",
      "[TRAIN] iter=2240/10000 avg_loss=0.0338 avg_kappa=1.0000\n",
      "[TRAIN] iter=2250/10000 avg_loss=0.1878 avg_kappa=0.9775\n",
      "[TRAIN] iter=2260/10000 avg_loss=0.2179 avg_kappa=0.8951\n",
      "[TRAIN] iter=2270/10000 avg_loss=0.1092 avg_kappa=0.9820\n",
      "[TRAIN] iter=2280/10000 avg_loss=0.2668 avg_kappa=0.9802\n",
      "[TRAIN] iter=2290/10000 avg_loss=0.0410 avg_kappa=0.9805\n",
      "[TRAIN] iter=2300/10000 avg_loss=0.1631 avg_kappa=0.9031\n",
      "[EVAL ] iter=2300/10000 avg_loss=0.8155 kappa=0.7500\n",
      "[TRAIN] iter=2310/10000 avg_loss=0.0505 avg_kappa=1.0000\n",
      "[TRAIN] iter=2320/10000 avg_loss=0.0584 avg_kappa=1.0000\n",
      "[TRAIN] iter=2330/10000 avg_loss=0.0535 avg_kappa=0.9656\n",
      "[TRAIN] iter=2340/10000 avg_loss=0.1945 avg_kappa=0.9583\n",
      "[TRAIN] iter=2350/10000 avg_loss=0.1197 avg_kappa=0.9631\n",
      "[TRAIN] iter=2360/10000 avg_loss=0.1445 avg_kappa=0.9623\n",
      "[TRAIN] iter=2370/10000 avg_loss=0.0390 avg_kappa=1.0000\n",
      "[TRAIN] iter=2380/10000 avg_loss=0.0206 avg_kappa=1.0000\n",
      "[TRAIN] iter=2390/10000 avg_loss=0.0178 avg_kappa=1.0000\n",
      "[TRAIN] iter=2400/10000 avg_loss=0.0151 avg_kappa=1.0000\n",
      "[EVAL ] iter=2400/10000 avg_loss=0.8920 kappa=0.6653\n",
      "[TRAIN] iter=2410/10000 avg_loss=0.0093 avg_kappa=1.0000\n",
      "[TRAIN] iter=2420/10000 avg_loss=0.0245 avg_kappa=1.0000\n",
      "[TRAIN] iter=2430/10000 avg_loss=0.0093 avg_kappa=1.0000\n",
      "[TRAIN] iter=2440/10000 avg_loss=0.0136 avg_kappa=1.0000\n",
      "[TRAIN] iter=2450/10000 avg_loss=0.0041 avg_kappa=1.0000\n",
      "[TRAIN] iter=2460/10000 avg_loss=0.0144 avg_kappa=1.0000\n",
      "[TRAIN] iter=2470/10000 avg_loss=0.0295 avg_kappa=1.0000\n",
      "[TRAIN] iter=2480/10000 avg_loss=0.0136 avg_kappa=1.0000\n",
      "[TRAIN] iter=2490/10000 avg_loss=0.0135 avg_kappa=1.0000\n",
      "[TRAIN] iter=2500/10000 avg_loss=0.1334 avg_kappa=0.9809\n",
      "[EVAL ] iter=2500/10000 avg_loss=0.9190 kappa=0.6887\n",
      "[TRAIN] iter=2510/10000 avg_loss=0.0240 avg_kappa=1.0000\n",
      "[TRAIN] iter=2520/10000 avg_loss=0.0981 avg_kappa=0.9657\n",
      "[TRAIN] iter=2530/10000 avg_loss=0.0819 avg_kappa=0.9653\n",
      "[TRAIN] iter=2540/10000 avg_loss=0.0158 avg_kappa=1.0000\n",
      "[TRAIN] iter=2550/10000 avg_loss=0.1543 avg_kappa=0.9272\n",
      "[TRAIN] iter=2560/10000 avg_loss=0.0849 avg_kappa=0.9807\n",
      "[TRAIN] iter=2570/10000 avg_loss=0.2418 avg_kappa=0.9479\n",
      "[TRAIN] iter=2580/10000 avg_loss=0.3599 avg_kappa=0.8855\n",
      "[TRAIN] iter=2590/10000 avg_loss=0.0260 avg_kappa=1.0000\n",
      "[TRAIN] iter=2600/10000 avg_loss=0.1016 avg_kappa=0.9591\n",
      "[EVAL ] iter=2600/10000 avg_loss=0.5050 kappa=0.7287\n",
      "[TRAIN] iter=2610/10000 avg_loss=0.0450 avg_kappa=1.0000\n",
      "[TRAIN] iter=2620/10000 avg_loss=0.3051 avg_kappa=0.8980\n",
      "[TRAIN] iter=2630/10000 avg_loss=0.3059 avg_kappa=0.8936\n",
      "[TRAIN] iter=2640/10000 avg_loss=0.0657 avg_kappa=0.9779\n",
      "[TRAIN] iter=2650/10000 avg_loss=0.0296 avg_kappa=1.0000\n",
      "[TRAIN] iter=2660/10000 avg_loss=0.0485 avg_kappa=1.0000\n",
      "[TRAIN] iter=2670/10000 avg_loss=0.0263 avg_kappa=1.0000\n",
      "[TRAIN] iter=2680/10000 avg_loss=0.0200 avg_kappa=1.0000\n",
      "[TRAIN] iter=2690/10000 avg_loss=0.0417 avg_kappa=1.0000\n",
      "[TRAIN] iter=2700/10000 avg_loss=0.0335 avg_kappa=0.9789\n",
      "[EVAL ] iter=2700/10000 avg_loss=0.6814 kappa=0.6911\n",
      "[TRAIN] iter=2710/10000 avg_loss=0.0333 avg_kappa=1.0000\n",
      "[TRAIN] iter=2720/10000 avg_loss=0.0313 avg_kappa=1.0000\n",
      "[TRAIN] iter=2730/10000 avg_loss=0.0151 avg_kappa=1.0000\n",
      "[TRAIN] iter=2740/10000 avg_loss=0.0223 avg_kappa=1.0000\n",
      "[TRAIN] iter=2750/10000 avg_loss=0.0158 avg_kappa=1.0000\n",
      "[TRAIN] iter=2760/10000 avg_loss=0.0270 avg_kappa=1.0000\n",
      "[TRAIN] iter=2770/10000 avg_loss=0.1429 avg_kappa=0.9655\n",
      "[TRAIN] iter=2780/10000 avg_loss=0.0841 avg_kappa=0.9591\n",
      "[TRAIN] iter=2790/10000 avg_loss=0.2638 avg_kappa=0.9260\n",
      "[TRAIN] iter=2800/10000 avg_loss=0.1059 avg_kappa=0.9123\n",
      "[EVAL ] iter=2800/10000 avg_loss=0.6300 kappa=0.7083\n",
      "[TRAIN] iter=2810/10000 avg_loss=0.0997 avg_kappa=0.9815\n",
      "[TRAIN] iter=2820/10000 avg_loss=0.1674 avg_kappa=0.9623\n",
      "[TRAIN] iter=2830/10000 avg_loss=0.0779 avg_kappa=0.9801\n",
      "[TRAIN] iter=2840/10000 avg_loss=0.1835 avg_kappa=0.9115\n",
      "[TRAIN] iter=2850/10000 avg_loss=0.0936 avg_kappa=0.9660\n",
      "[TRAIN] iter=2860/10000 avg_loss=0.1975 avg_kappa=0.8077\n",
      "[TRAIN] iter=2870/10000 avg_loss=0.1139 avg_kappa=0.9044\n",
      "[TRAIN] iter=2880/10000 avg_loss=0.0529 avg_kappa=1.0000\n",
      "[TRAIN] iter=2890/10000 avg_loss=0.1472 avg_kappa=0.9151\n",
      "[TRAIN] iter=2900/10000 avg_loss=0.0212 avg_kappa=1.0000\n",
      "[EVAL ] iter=2900/10000 avg_loss=0.9034 kappa=0.3722\n",
      "[TRAIN] iter=2910/10000 avg_loss=0.1453 avg_kappa=0.8846\n",
      "[TRAIN] iter=2920/10000 avg_loss=0.0362 avg_kappa=1.0000\n",
      "[TRAIN] iter=2930/10000 avg_loss=0.0498 avg_kappa=0.9829\n",
      "[TRAIN] iter=2940/10000 avg_loss=0.0417 avg_kappa=0.9793\n",
      "[TRAIN] iter=2950/10000 avg_loss=0.0191 avg_kappa=1.0000\n",
      "[TRAIN] iter=2960/10000 avg_loss=0.0328 avg_kappa=0.9722\n",
      "[TRAIN] iter=2970/10000 avg_loss=0.0176 avg_kappa=1.0000\n",
      "[TRAIN] iter=2980/10000 avg_loss=0.0161 avg_kappa=1.0000\n",
      "[TRAIN] iter=2990/10000 avg_loss=0.0063 avg_kappa=1.0000\n",
      "[TRAIN] iter=3000/10000 avg_loss=0.0065 avg_kappa=1.0000\n",
      "[EVAL ] iter=3000/10000 avg_loss=0.6431 kappa=0.8030\n",
      "[TRAIN] iter=3010/10000 avg_loss=0.0120 avg_kappa=1.0000\n",
      "[TRAIN] iter=3020/10000 avg_loss=0.0047 avg_kappa=1.0000\n",
      "[TRAIN] iter=3030/10000 avg_loss=0.1047 avg_kappa=0.9000\n",
      "[TRAIN] iter=3040/10000 avg_loss=0.0145 avg_kappa=1.0000\n",
      "[TRAIN] iter=3050/10000 avg_loss=0.0258 avg_kappa=1.0000\n",
      "[TRAIN] iter=3060/10000 avg_loss=0.0335 avg_kappa=1.0000\n",
      "[TRAIN] iter=3070/10000 avg_loss=0.0102 avg_kappa=1.0000\n",
      "[TRAIN] iter=3080/10000 avg_loss=0.1051 avg_kappa=0.9554\n",
      "[TRAIN] iter=3090/10000 avg_loss=0.0275 avg_kappa=1.0000\n",
      "[TRAIN] iter=3100/10000 avg_loss=0.1260 avg_kappa=0.9811\n",
      "[EVAL ] iter=3100/10000 avg_loss=0.4054 kappa=0.7635\n",
      "[TRAIN] iter=3110/10000 avg_loss=0.0423 avg_kappa=1.0000\n",
      "[TRAIN] iter=3120/10000 avg_loss=0.0313 avg_kappa=1.0000\n",
      "[TRAIN] iter=3130/10000 avg_loss=0.0272 avg_kappa=1.0000\n",
      "[TRAIN] iter=3140/10000 avg_loss=0.0100 avg_kappa=1.0000\n",
      "[TRAIN] iter=3150/10000 avg_loss=0.0253 avg_kappa=1.0000\n",
      "[TRAIN] iter=3160/10000 avg_loss=0.0300 avg_kappa=0.9775\n",
      "[TRAIN] iter=3170/10000 avg_loss=0.0259 avg_kappa=0.9791\n",
      "[TRAIN] iter=3180/10000 avg_loss=0.0502 avg_kappa=0.9823\n",
      "[TRAIN] iter=3190/10000 avg_loss=0.0406 avg_kappa=0.9811\n",
      "[TRAIN] iter=3200/10000 avg_loss=0.0411 avg_kappa=1.0000\n",
      "[EVAL ] iter=3200/10000 avg_loss=1.1424 kappa=0.4595\n",
      "[TRAIN] iter=3210/10000 avg_loss=0.0301 avg_kappa=1.0000\n",
      "[TRAIN] iter=3220/10000 avg_loss=0.0952 avg_kappa=0.9823\n",
      "[TRAIN] iter=3230/10000 avg_loss=0.0136 avg_kappa=1.0000\n",
      "[TRAIN] iter=3240/10000 avg_loss=0.0177 avg_kappa=1.0000\n",
      "[TRAIN] iter=3250/10000 avg_loss=0.0072 avg_kappa=1.0000\n",
      "[TRAIN] iter=3260/10000 avg_loss=0.0104 avg_kappa=1.0000\n",
      "[TRAIN] iter=3270/10000 avg_loss=0.0155 avg_kappa=1.0000\n",
      "[TRAIN] iter=3280/10000 avg_loss=0.0134 avg_kappa=1.0000\n",
      "[TRAIN] iter=3290/10000 avg_loss=0.0100 avg_kappa=1.0000\n",
      "[TRAIN] iter=3300/10000 avg_loss=0.0073 avg_kappa=1.0000\n",
      "[EVAL ] iter=3300/10000 avg_loss=0.7347 kappa=0.7083\n",
      "[TRAIN] iter=3310/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=3320/10000 avg_loss=0.0133 avg_kappa=1.0000\n",
      "[TRAIN] iter=3330/10000 avg_loss=0.1674 avg_kappa=0.9828\n",
      "[TRAIN] iter=3340/10000 avg_loss=0.0110 avg_kappa=1.0000\n",
      "[TRAIN] iter=3350/10000 avg_loss=0.0194 avg_kappa=1.0000\n",
      "[TRAIN] iter=3360/10000 avg_loss=0.1079 avg_kappa=0.9791\n",
      "[TRAIN] iter=3370/10000 avg_loss=0.0161 avg_kappa=1.0000\n",
      "[TRAIN] iter=3380/10000 avg_loss=0.1744 avg_kappa=0.9775\n",
      "[TRAIN] iter=3390/10000 avg_loss=0.0796 avg_kappa=0.9775\n",
      "[TRAIN] iter=3400/10000 avg_loss=0.0857 avg_kappa=0.9824\n",
      "[EVAL ] iter=3400/10000 avg_loss=0.4291 kappa=0.7683\n",
      "[TRAIN] iter=3410/10000 avg_loss=0.0190 avg_kappa=1.0000\n",
      "[TRAIN] iter=3420/10000 avg_loss=0.0183 avg_kappa=1.0000\n",
      "[TRAIN] iter=3430/10000 avg_loss=0.0278 avg_kappa=1.0000\n",
      "[TRAIN] iter=3440/10000 avg_loss=0.0123 avg_kappa=1.0000\n",
      "[TRAIN] iter=3450/10000 avg_loss=0.0184 avg_kappa=1.0000\n",
      "[TRAIN] iter=3460/10000 avg_loss=0.0057 avg_kappa=1.0000\n",
      "[TRAIN] iter=3470/10000 avg_loss=0.0028 avg_kappa=1.0000\n",
      "[TRAIN] iter=3480/10000 avg_loss=0.0080 avg_kappa=1.0000\n",
      "[TRAIN] iter=3490/10000 avg_loss=0.0265 avg_kappa=0.9320\n",
      "[TRAIN] iter=3500/10000 avg_loss=0.0591 avg_kappa=0.9793\n",
      "[EVAL ] iter=3500/10000 avg_loss=0.6015 kappa=0.7287\n",
      "[TRAIN] iter=3510/10000 avg_loss=0.0078 avg_kappa=1.0000\n",
      "[TRAIN] iter=3520/10000 avg_loss=0.0132 avg_kappa=1.0000\n",
      "[TRAIN] iter=3530/10000 avg_loss=0.0056 avg_kappa=1.0000\n",
      "[TRAIN] iter=3540/10000 avg_loss=0.0079 avg_kappa=1.0000\n",
      "[TRAIN] iter=3550/10000 avg_loss=0.0111 avg_kappa=1.0000\n",
      "[TRAIN] iter=3560/10000 avg_loss=0.0070 avg_kappa=1.0000\n",
      "[TRAIN] iter=3570/10000 avg_loss=0.0024 avg_kappa=1.0000\n",
      "[TRAIN] iter=3580/10000 avg_loss=0.0072 avg_kappa=1.0000\n",
      "[TRAIN] iter=3590/10000 avg_loss=0.0074 avg_kappa=1.0000\n",
      "[TRAIN] iter=3600/10000 avg_loss=0.0052 avg_kappa=1.0000\n",
      "[EVAL ] iter=3600/10000 avg_loss=0.6038 kappa=0.7287\n",
      "[TRAIN] iter=3610/10000 avg_loss=0.0067 avg_kappa=1.0000\n",
      "[TRAIN] iter=3620/10000 avg_loss=0.0017 avg_kappa=1.0000\n",
      "[TRAIN] iter=3630/10000 avg_loss=0.0355 avg_kappa=1.0000\n",
      "[TRAIN] iter=3640/10000 avg_loss=0.0052 avg_kappa=1.0000\n",
      "[TRAIN] iter=3650/10000 avg_loss=0.0070 avg_kappa=1.0000\n",
      "[TRAIN] iter=3660/10000 avg_loss=0.0030 avg_kappa=1.0000\n",
      "[TRAIN] iter=3670/10000 avg_loss=0.0040 avg_kappa=1.0000\n",
      "[TRAIN] iter=3680/10000 avg_loss=0.0071 avg_kappa=1.0000\n",
      "[TRAIN] iter=3690/10000 avg_loss=0.0039 avg_kappa=1.0000\n",
      "[TRAIN] iter=3700/10000 avg_loss=0.0047 avg_kappa=1.0000\n",
      "[EVAL ] iter=3700/10000 avg_loss=0.9920 kappa=0.6911\n",
      "[TRAIN] iter=3710/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=3720/10000 avg_loss=0.0030 avg_kappa=1.0000\n",
      "[TRAIN] iter=3730/10000 avg_loss=0.0016 avg_kappa=1.0000\n",
      "[TRAIN] iter=3740/10000 avg_loss=0.0021 avg_kappa=1.0000\n",
      "[TRAIN] iter=3750/10000 avg_loss=0.0045 avg_kappa=1.0000\n",
      "[TRAIN] iter=3760/10000 avg_loss=0.0013 avg_kappa=1.0000\n",
      "[TRAIN] iter=3770/10000 avg_loss=0.0021 avg_kappa=1.0000\n",
      "[TRAIN] iter=3780/10000 avg_loss=0.0534 avg_kappa=0.9796\n",
      "[TRAIN] iter=3790/10000 avg_loss=0.0037 avg_kappa=1.0000\n",
      "[TRAIN] iter=3800/10000 avg_loss=0.0067 avg_kappa=1.0000\n",
      "[EVAL ] iter=3800/10000 avg_loss=1.1701 kappa=0.6911\n",
      "[TRAIN] iter=3810/10000 avg_loss=0.0055 avg_kappa=1.0000\n",
      "[TRAIN] iter=3820/10000 avg_loss=0.0698 avg_kappa=0.9798\n",
      "[TRAIN] iter=3830/10000 avg_loss=0.0025 avg_kappa=1.0000\n",
      "[TRAIN] iter=3840/10000 avg_loss=0.0762 avg_kappa=0.9805\n",
      "[TRAIN] iter=3850/10000 avg_loss=0.1130 avg_kappa=0.9805\n",
      "[TRAIN] iter=3860/10000 avg_loss=0.0302 avg_kappa=1.0000\n",
      "[TRAIN] iter=3870/10000 avg_loss=0.0062 avg_kappa=1.0000\n",
      "[TRAIN] iter=3880/10000 avg_loss=0.0129 avg_kappa=1.0000\n",
      "[TRAIN] iter=3890/10000 avg_loss=0.0189 avg_kappa=1.0000\n",
      "[TRAIN] iter=3900/10000 avg_loss=0.0060 avg_kappa=1.0000\n",
      "[EVAL ] iter=3900/10000 avg_loss=1.0229 kappa=0.6512\n",
      "[TRAIN] iter=3910/10000 avg_loss=0.0107 avg_kappa=1.0000\n",
      "[TRAIN] iter=3920/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=3930/10000 avg_loss=0.0035 avg_kappa=1.0000\n",
      "[TRAIN] iter=3940/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=3950/10000 avg_loss=0.0035 avg_kappa=1.0000\n",
      "[TRAIN] iter=3960/10000 avg_loss=0.0019 avg_kappa=1.0000\n",
      "[TRAIN] iter=3970/10000 avg_loss=0.0028 avg_kappa=1.0000\n",
      "[TRAIN] iter=3980/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=3990/10000 avg_loss=0.0548 avg_kappa=0.9803\n",
      "[TRAIN] iter=4000/10000 avg_loss=0.0221 avg_kappa=1.0000\n",
      "[EVAL ] iter=4000/10000 avg_loss=1.0189 kappa=0.6218\n",
      "[TRAIN] iter=4010/10000 avg_loss=0.0487 avg_kappa=0.9791\n",
      "[TRAIN] iter=4020/10000 avg_loss=0.0137 avg_kappa=1.0000\n",
      "[TRAIN] iter=4030/10000 avg_loss=0.0087 avg_kappa=1.0000\n",
      "[TRAIN] iter=4040/10000 avg_loss=0.1577 avg_kappa=0.9638\n",
      "[TRAIN] iter=4050/10000 avg_loss=0.1807 avg_kappa=0.9341\n",
      "[TRAIN] iter=4060/10000 avg_loss=0.0169 avg_kappa=1.0000\n",
      "[TRAIN] iter=4070/10000 avg_loss=0.1550 avg_kappa=0.9642\n",
      "[TRAIN] iter=4080/10000 avg_loss=0.0495 avg_kappa=1.0000\n",
      "[TRAIN] iter=4090/10000 avg_loss=0.0528 avg_kappa=0.9832\n",
      "[TRAIN] iter=4100/10000 avg_loss=0.1100 avg_kappa=0.8794\n",
      "[EVAL ] iter=4100/10000 avg_loss=0.9780 kappa=0.5608\n",
      "[TRAIN] iter=4110/10000 avg_loss=0.1750 avg_kappa=0.9405\n",
      "[TRAIN] iter=4120/10000 avg_loss=0.3171 avg_kappa=0.9648\n",
      "[TRAIN] iter=4130/10000 avg_loss=0.0434 avg_kappa=1.0000\n",
      "[TRAIN] iter=4140/10000 avg_loss=0.1947 avg_kappa=0.8692\n",
      "[TRAIN] iter=4150/10000 avg_loss=0.0495 avg_kappa=0.9813\n",
      "[TRAIN] iter=4160/10000 avg_loss=0.2526 avg_kappa=0.8641\n",
      "[TRAIN] iter=4170/10000 avg_loss=0.0442 avg_kappa=1.0000\n",
      "[TRAIN] iter=4180/10000 avg_loss=0.1405 avg_kappa=0.9004\n",
      "[TRAIN] iter=4190/10000 avg_loss=0.2439 avg_kappa=0.8022\n",
      "[TRAIN] iter=4200/10000 avg_loss=0.0448 avg_kappa=1.0000\n",
      "[EVAL ] iter=4200/10000 avg_loss=0.7902 kappa=0.5851\n",
      "[TRAIN] iter=4210/10000 avg_loss=0.2831 avg_kappa=0.9383\n",
      "[TRAIN] iter=4220/10000 avg_loss=0.0933 avg_kappa=0.9826\n",
      "[TRAIN] iter=4230/10000 avg_loss=0.4560 avg_kappa=0.8933\n",
      "[TRAIN] iter=4240/10000 avg_loss=0.1437 avg_kappa=0.9390\n",
      "[TRAIN] iter=4250/10000 avg_loss=0.0423 avg_kappa=1.0000\n",
      "[TRAIN] iter=4260/10000 avg_loss=0.0814 avg_kappa=0.9824\n",
      "[TRAIN] iter=4270/10000 avg_loss=0.0971 avg_kappa=0.9648\n",
      "[TRAIN] iter=4280/10000 avg_loss=0.0262 avg_kappa=1.0000\n",
      "[TRAIN] iter=4290/10000 avg_loss=0.0077 avg_kappa=1.0000\n",
      "[TRAIN] iter=4300/10000 avg_loss=0.0108 avg_kappa=1.0000\n",
      "[EVAL ] iter=4300/10000 avg_loss=0.7130 kappa=0.7083\n",
      "[TRAIN] iter=4310/10000 avg_loss=0.0070 avg_kappa=1.0000\n",
      "[TRAIN] iter=4320/10000 avg_loss=0.0297 avg_kappa=1.0000\n",
      "[TRAIN] iter=4330/10000 avg_loss=0.0291 avg_kappa=1.0000\n",
      "[TRAIN] iter=4340/10000 avg_loss=0.0099 avg_kappa=1.0000\n",
      "[TRAIN] iter=4350/10000 avg_loss=0.0218 avg_kappa=1.0000\n",
      "[TRAIN] iter=4360/10000 avg_loss=0.0060 avg_kappa=1.0000\n",
      "[TRAIN] iter=4370/10000 avg_loss=0.0025 avg_kappa=1.0000\n",
      "[TRAIN] iter=4380/10000 avg_loss=0.0378 avg_kappa=0.9798\n",
      "[TRAIN] iter=4390/10000 avg_loss=0.0227 avg_kappa=1.0000\n",
      "[TRAIN] iter=4400/10000 avg_loss=0.0051 avg_kappa=1.0000\n",
      "[EVAL ] iter=4400/10000 avg_loss=1.0538 kappa=0.5045\n",
      "[TRAIN] iter=4410/10000 avg_loss=0.0032 avg_kappa=1.0000\n",
      "[TRAIN] iter=4420/10000 avg_loss=0.0064 avg_kappa=1.0000\n",
      "[TRAIN] iter=4430/10000 avg_loss=0.0223 avg_kappa=1.0000\n",
      "[TRAIN] iter=4440/10000 avg_loss=0.0464 avg_kappa=0.9815\n",
      "[TRAIN] iter=4450/10000 avg_loss=0.0505 avg_kappa=0.9794\n",
      "[TRAIN] iter=4460/10000 avg_loss=0.0477 avg_kappa=0.9828\n",
      "[TRAIN] iter=4470/10000 avg_loss=0.0268 avg_kappa=1.0000\n",
      "[TRAIN] iter=4480/10000 avg_loss=0.1345 avg_kappa=0.8957\n",
      "[TRAIN] iter=4490/10000 avg_loss=0.0151 avg_kappa=1.0000\n",
      "[TRAIN] iter=4500/10000 avg_loss=0.0197 avg_kappa=1.0000\n",
      "[EVAL ] iter=4500/10000 avg_loss=0.6599 kappa=0.6250\n",
      "[TRAIN] iter=4510/10000 avg_loss=0.0123 avg_kappa=1.0000\n",
      "[TRAIN] iter=4520/10000 avg_loss=0.0063 avg_kappa=1.0000\n",
      "[TRAIN] iter=4530/10000 avg_loss=0.0537 avg_kappa=0.9782\n",
      "[TRAIN] iter=4540/10000 avg_loss=0.0497 avg_kappa=0.9829\n",
      "[TRAIN] iter=4550/10000 avg_loss=0.0284 avg_kappa=1.0000\n",
      "[TRAIN] iter=4560/10000 avg_loss=0.0347 avg_kappa=0.9789\n",
      "[TRAIN] iter=4570/10000 avg_loss=0.0082 avg_kappa=1.0000\n",
      "[TRAIN] iter=4580/10000 avg_loss=0.0147 avg_kappa=1.0000\n",
      "[TRAIN] iter=4590/10000 avg_loss=0.0040 avg_kappa=1.0000\n",
      "[TRAIN] iter=4600/10000 avg_loss=0.0081 avg_kappa=1.0000\n",
      "[EVAL ] iter=4600/10000 avg_loss=0.5871 kappa=0.6818\n",
      "[TRAIN] iter=4610/10000 avg_loss=0.0037 avg_kappa=1.0000\n",
      "[TRAIN] iter=4620/10000 avg_loss=0.0061 avg_kappa=1.0000\n",
      "[TRAIN] iter=4630/10000 avg_loss=0.0096 avg_kappa=1.0000\n",
      "[TRAIN] iter=4640/10000 avg_loss=0.0065 avg_kappa=1.0000\n",
      "[TRAIN] iter=4650/10000 avg_loss=0.0357 avg_kappa=0.9820\n",
      "[TRAIN] iter=4660/10000 avg_loss=0.0098 avg_kappa=1.0000\n",
      "[TRAIN] iter=4670/10000 avg_loss=0.0191 avg_kappa=1.0000\n",
      "[TRAIN] iter=4680/10000 avg_loss=0.0042 avg_kappa=1.0000\n",
      "[TRAIN] iter=4690/10000 avg_loss=0.0028 avg_kappa=1.0000\n",
      "[TRAIN] iter=4700/10000 avg_loss=0.0012 avg_kappa=1.0000\n",
      "[EVAL ] iter=4700/10000 avg_loss=0.7893 kappa=0.6653\n",
      "[TRAIN] iter=4710/10000 avg_loss=0.0028 avg_kappa=1.0000\n",
      "[TRAIN] iter=4720/10000 avg_loss=0.0055 avg_kappa=1.0000\n",
      "[TRAIN] iter=4730/10000 avg_loss=0.0017 avg_kappa=1.0000\n",
      "[TRAIN] iter=4740/10000 avg_loss=0.0040 avg_kappa=1.0000\n",
      "[TRAIN] iter=4750/10000 avg_loss=0.0013 avg_kappa=1.0000\n",
      "[TRAIN] iter=4760/10000 avg_loss=0.0026 avg_kappa=1.0000\n",
      "[TRAIN] iter=4770/10000 avg_loss=0.0090 avg_kappa=1.0000\n",
      "[TRAIN] iter=4780/10000 avg_loss=0.0120 avg_kappa=1.0000\n",
      "[TRAIN] iter=4790/10000 avg_loss=0.0016 avg_kappa=1.0000\n",
      "[TRAIN] iter=4800/10000 avg_loss=0.0015 avg_kappa=1.0000\n",
      "[EVAL ] iter=4800/10000 avg_loss=0.7913 kappa=0.6020\n",
      "[TRAIN] iter=4810/10000 avg_loss=0.0043 avg_kappa=1.0000\n",
      "[TRAIN] iter=4820/10000 avg_loss=0.0012 avg_kappa=1.0000\n",
      "[TRAIN] iter=4830/10000 avg_loss=0.0020 avg_kappa=1.0000\n",
      "[TRAIN] iter=4840/10000 avg_loss=0.0017 avg_kappa=1.0000\n",
      "[TRAIN] iter=4850/10000 avg_loss=0.0018 avg_kappa=1.0000\n",
      "[TRAIN] iter=4860/10000 avg_loss=0.0029 avg_kappa=1.0000\n",
      "[TRAIN] iter=4870/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=4880/10000 avg_loss=0.0044 avg_kappa=1.0000\n",
      "[TRAIN] iter=4890/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=4900/10000 avg_loss=0.0030 avg_kappa=1.0000\n",
      "[EVAL ] iter=4900/10000 avg_loss=0.6877 kappa=0.7490\n",
      "[TRAIN] iter=4910/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=4920/10000 avg_loss=0.0013 avg_kappa=1.0000\n",
      "[TRAIN] iter=4930/10000 avg_loss=0.0021 avg_kappa=1.0000\n",
      "[TRAIN] iter=4940/10000 avg_loss=0.0053 avg_kappa=1.0000\n",
      "[TRAIN] iter=4950/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=4960/10000 avg_loss=0.0018 avg_kappa=1.0000\n",
      "[TRAIN] iter=4970/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=4980/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=4990/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=5000/10000 avg_loss=0.0026 avg_kappa=1.0000\n",
      "[EVAL ] iter=5000/10000 avg_loss=0.7427 kappa=0.7083\n",
      "[TRAIN] iter=5010/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=5020/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=5030/10000 avg_loss=0.0018 avg_kappa=1.0000\n",
      "[TRAIN] iter=5040/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=5050/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=5060/10000 avg_loss=0.0012 avg_kappa=1.0000\n",
      "[TRAIN] iter=5070/10000 avg_loss=0.0020 avg_kappa=1.0000\n",
      "[TRAIN] iter=5080/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=5090/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=5100/10000 avg_loss=0.0013 avg_kappa=1.0000\n",
      "[EVAL ] iter=5100/10000 avg_loss=0.7069 kappa=0.6911\n",
      "[TRAIN] iter=5110/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=5120/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=5130/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=5140/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=5150/10000 avg_loss=0.0632 avg_kappa=0.9802\n",
      "[TRAIN] iter=5160/10000 avg_loss=0.0129 avg_kappa=1.0000\n",
      "[TRAIN] iter=5170/10000 avg_loss=0.0198 avg_kappa=1.0000\n",
      "[TRAIN] iter=5180/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=5190/10000 avg_loss=0.0013 avg_kappa=1.0000\n",
      "[TRAIN] iter=5200/10000 avg_loss=0.0014 avg_kappa=1.0000\n",
      "[EVAL ] iter=5200/10000 avg_loss=0.5286 kappa=0.7490\n",
      "[TRAIN] iter=5210/10000 avg_loss=0.0025 avg_kappa=1.0000\n",
      "[TRAIN] iter=5220/10000 avg_loss=0.0201 avg_kappa=1.0000\n",
      "[TRAIN] iter=5230/10000 avg_loss=0.0053 avg_kappa=1.0000\n",
      "[TRAIN] iter=5240/10000 avg_loss=0.1520 avg_kappa=0.9648\n",
      "[TRAIN] iter=5250/10000 avg_loss=0.1834 avg_kappa=0.9456\n",
      "[TRAIN] iter=5260/10000 avg_loss=0.1904 avg_kappa=0.8801\n",
      "[TRAIN] iter=5270/10000 avg_loss=0.0798 avg_kappa=0.8925\n",
      "[TRAIN] iter=5280/10000 avg_loss=0.0325 avg_kappa=1.0000\n",
      "[TRAIN] iter=5290/10000 avg_loss=0.1393 avg_kappa=0.9640\n",
      "[TRAIN] iter=5300/10000 avg_loss=0.0654 avg_kappa=0.9810\n",
      "[EVAL ] iter=5300/10000 avg_loss=1.4794 kappa=0.7748\n",
      "[TRAIN] iter=5310/10000 avg_loss=0.2041 avg_kappa=0.9794\n",
      "[TRAIN] iter=5320/10000 avg_loss=0.1237 avg_kappa=0.9828\n",
      "[TRAIN] iter=5330/10000 avg_loss=0.0341 avg_kappa=1.0000\n",
      "[TRAIN] iter=5340/10000 avg_loss=0.2275 avg_kappa=0.8818\n",
      "[TRAIN] iter=5350/10000 avg_loss=0.1951 avg_kappa=0.9640\n",
      "[TRAIN] iter=5360/10000 avg_loss=0.1297 avg_kappa=0.9630\n",
      "[TRAIN] iter=5370/10000 avg_loss=0.0258 avg_kappa=1.0000\n",
      "[TRAIN] iter=5380/10000 avg_loss=0.0986 avg_kappa=0.9630\n",
      "[TRAIN] iter=5390/10000 avg_loss=0.1177 avg_kappa=0.9826\n",
      "[TRAIN] iter=5400/10000 avg_loss=0.1340 avg_kappa=0.9006\n",
      "[EVAL ] iter=5400/10000 avg_loss=0.8289 kappa=0.7635\n",
      "[TRAIN] iter=5410/10000 avg_loss=0.1578 avg_kappa=0.8713\n",
      "[TRAIN] iter=5420/10000 avg_loss=0.1255 avg_kappa=0.9468\n",
      "[TRAIN] iter=5430/10000 avg_loss=0.0748 avg_kappa=0.9828\n",
      "[TRAIN] iter=5440/10000 avg_loss=0.1313 avg_kappa=0.9592\n",
      "[TRAIN] iter=5450/10000 avg_loss=0.0476 avg_kappa=0.9828\n",
      "[TRAIN] iter=5460/10000 avg_loss=0.0686 avg_kappa=0.9794\n",
      "[TRAIN] iter=5470/10000 avg_loss=0.0172 avg_kappa=1.0000\n",
      "[TRAIN] iter=5480/10000 avg_loss=0.1287 avg_kappa=0.9446\n",
      "[TRAIN] iter=5490/10000 avg_loss=0.0383 avg_kappa=1.0000\n",
      "[TRAIN] iter=5500/10000 avg_loss=0.0282 avg_kappa=1.0000\n",
      "[EVAL ] iter=5500/10000 avg_loss=0.8483 kappa=0.7635\n",
      "[TRAIN] iter=5510/10000 avg_loss=0.0320 avg_kappa=1.0000\n",
      "[TRAIN] iter=5520/10000 avg_loss=0.0107 avg_kappa=1.0000\n",
      "[TRAIN] iter=5530/10000 avg_loss=0.0138 avg_kappa=1.0000\n",
      "[TRAIN] iter=5540/10000 avg_loss=0.0270 avg_kappa=1.0000\n",
      "[TRAIN] iter=5550/10000 avg_loss=0.0183 avg_kappa=1.0000\n",
      "[TRAIN] iter=5560/10000 avg_loss=0.0045 avg_kappa=1.0000\n",
      "[TRAIN] iter=5570/10000 avg_loss=0.0081 avg_kappa=1.0000\n",
      "[TRAIN] iter=5580/10000 avg_loss=0.0121 avg_kappa=1.0000\n",
      "[TRAIN] iter=5590/10000 avg_loss=0.0117 avg_kappa=1.0000\n",
      "[TRAIN] iter=5600/10000 avg_loss=0.0100 avg_kappa=1.0000\n",
      "[EVAL ] iter=5600/10000 avg_loss=0.8398 kappa=0.5545\n",
      "[TRAIN] iter=5610/10000 avg_loss=0.0019 avg_kappa=1.0000\n",
      "[TRAIN] iter=5620/10000 avg_loss=0.0044 avg_kappa=1.0000\n",
      "[TRAIN] iter=5630/10000 avg_loss=0.0027 avg_kappa=1.0000\n",
      "[TRAIN] iter=5640/10000 avg_loss=0.0042 avg_kappa=1.0000\n",
      "[TRAIN] iter=5650/10000 avg_loss=0.0175 avg_kappa=1.0000\n",
      "[TRAIN] iter=5660/10000 avg_loss=0.0020 avg_kappa=1.0000\n",
      "[TRAIN] iter=5670/10000 avg_loss=0.0036 avg_kappa=1.0000\n",
      "[TRAIN] iter=5680/10000 avg_loss=0.0067 avg_kappa=1.0000\n",
      "[TRAIN] iter=5690/10000 avg_loss=0.0038 avg_kappa=1.0000\n",
      "[TRAIN] iter=5700/10000 avg_loss=0.0020 avg_kappa=1.0000\n",
      "[EVAL ] iter=5700/10000 avg_loss=0.7259 kappa=0.7083\n",
      "[TRAIN] iter=5710/10000 avg_loss=0.0058 avg_kappa=1.0000\n",
      "[TRAIN] iter=5720/10000 avg_loss=0.0030 avg_kappa=1.0000\n",
      "[TRAIN] iter=5730/10000 avg_loss=0.0017 avg_kappa=1.0000\n",
      "[TRAIN] iter=5740/10000 avg_loss=0.0037 avg_kappa=1.0000\n",
      "[TRAIN] iter=5750/10000 avg_loss=0.0020 avg_kappa=1.0000\n",
      "[TRAIN] iter=5760/10000 avg_loss=0.0022 avg_kappa=1.0000\n",
      "[TRAIN] iter=5770/10000 avg_loss=0.0023 avg_kappa=1.0000\n",
      "[TRAIN] iter=5780/10000 avg_loss=0.0021 avg_kappa=1.0000\n",
      "[TRAIN] iter=5790/10000 avg_loss=0.0326 avg_kappa=0.9801\n",
      "[TRAIN] iter=5800/10000 avg_loss=0.0032 avg_kappa=1.0000\n",
      "[EVAL ] iter=5800/10000 avg_loss=0.8898 kappa=0.6911\n",
      "[TRAIN] iter=5810/10000 avg_loss=0.0119 avg_kappa=1.0000\n",
      "[TRAIN] iter=5820/10000 avg_loss=0.0021 avg_kappa=1.0000\n",
      "[TRAIN] iter=5830/10000 avg_loss=0.0061 avg_kappa=1.0000\n",
      "[TRAIN] iter=5840/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=5850/10000 avg_loss=0.0059 avg_kappa=1.0000\n",
      "[TRAIN] iter=5860/10000 avg_loss=0.0066 avg_kappa=1.0000\n",
      "[TRAIN] iter=5870/10000 avg_loss=0.0023 avg_kappa=1.0000\n",
      "[TRAIN] iter=5880/10000 avg_loss=0.0013 avg_kappa=1.0000\n",
      "[TRAIN] iter=5890/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=5900/10000 avg_loss=0.0025 avg_kappa=1.0000\n",
      "[EVAL ] iter=5900/10000 avg_loss=1.1051 kappa=0.6250\n",
      "[TRAIN] iter=5910/10000 avg_loss=0.0027 avg_kappa=1.0000\n",
      "[TRAIN] iter=5920/10000 avg_loss=0.0103 avg_kappa=1.0000\n",
      "[TRAIN] iter=5930/10000 avg_loss=0.0153 avg_kappa=1.0000\n",
      "[TRAIN] iter=5940/10000 avg_loss=0.0087 avg_kappa=1.0000\n",
      "[TRAIN] iter=5950/10000 avg_loss=0.0047 avg_kappa=1.0000\n",
      "[TRAIN] iter=5960/10000 avg_loss=0.0245 avg_kappa=0.9811\n",
      "[TRAIN] iter=5970/10000 avg_loss=0.0052 avg_kappa=1.0000\n",
      "[TRAIN] iter=5980/10000 avg_loss=0.0037 avg_kappa=1.0000\n",
      "[TRAIN] iter=5990/10000 avg_loss=0.0014 avg_kappa=1.0000\n",
      "[TRAIN] iter=6000/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[EVAL ] iter=6000/10000 avg_loss=0.9333 kappa=0.7083\n",
      "[TRAIN] iter=6010/10000 avg_loss=0.0015 avg_kappa=1.0000\n",
      "[TRAIN] iter=6020/10000 avg_loss=0.0025 avg_kappa=1.0000\n",
      "[TRAIN] iter=6030/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=6040/10000 avg_loss=0.0034 avg_kappa=1.0000\n",
      "[TRAIN] iter=6050/10000 avg_loss=0.0014 avg_kappa=1.0000\n",
      "[TRAIN] iter=6060/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=6070/10000 avg_loss=0.0054 avg_kappa=1.0000\n",
      "[TRAIN] iter=6080/10000 avg_loss=0.0020 avg_kappa=1.0000\n",
      "[TRAIN] iter=6090/10000 avg_loss=0.1207 avg_kappa=0.9081\n",
      "[TRAIN] iter=6100/10000 avg_loss=0.0061 avg_kappa=1.0000\n",
      "[EVAL ] iter=6100/10000 avg_loss=1.7302 kappa=0.4086\n",
      "[TRAIN] iter=6110/10000 avg_loss=0.0313 avg_kappa=0.9821\n",
      "[TRAIN] iter=6120/10000 avg_loss=0.0817 avg_kappa=0.9791\n",
      "[TRAIN] iter=6130/10000 avg_loss=0.1003 avg_kappa=0.9246\n",
      "[TRAIN] iter=6140/10000 avg_loss=0.1174 avg_kappa=0.9079\n",
      "[TRAIN] iter=6150/10000 avg_loss=0.0474 avg_kappa=1.0000\n",
      "[TRAIN] iter=6160/10000 avg_loss=0.2948 avg_kappa=0.8406\n",
      "[TRAIN] iter=6170/10000 avg_loss=0.0973 avg_kappa=0.8925\n",
      "[TRAIN] iter=6180/10000 avg_loss=0.0237 avg_kappa=1.0000\n",
      "[TRAIN] iter=6190/10000 avg_loss=0.1266 avg_kappa=0.9565\n",
      "[TRAIN] iter=6200/10000 avg_loss=0.0738 avg_kappa=0.9830\n",
      "[EVAL ] iter=6200/10000 avg_loss=0.7817 kappa=0.5402\n",
      "[TRAIN] iter=6210/10000 avg_loss=0.0907 avg_kappa=0.9324\n",
      "[TRAIN] iter=6220/10000 avg_loss=0.0641 avg_kappa=0.9837\n",
      "[TRAIN] iter=6230/10000 avg_loss=0.1373 avg_kappa=0.9214\n",
      "[TRAIN] iter=6240/10000 avg_loss=0.0645 avg_kappa=0.9769\n",
      "[TRAIN] iter=6250/10000 avg_loss=0.0400 avg_kappa=1.0000\n",
      "[TRAIN] iter=6260/10000 avg_loss=0.0339 avg_kappa=1.0000\n",
      "[TRAIN] iter=6270/10000 avg_loss=0.0068 avg_kappa=1.0000\n",
      "[TRAIN] iter=6280/10000 avg_loss=0.1093 avg_kappa=0.9642\n",
      "[TRAIN] iter=6290/10000 avg_loss=0.0716 avg_kappa=0.9811\n",
      "[TRAIN] iter=6300/10000 avg_loss=0.0173 avg_kappa=1.0000\n",
      "[EVAL ] iter=6300/10000 avg_loss=0.8568 kappa=0.5045\n",
      "[TRAIN] iter=6310/10000 avg_loss=0.3057 avg_kappa=0.9411\n",
      "[TRAIN] iter=6320/10000 avg_loss=0.0319 avg_kappa=1.0000\n",
      "[TRAIN] iter=6330/10000 avg_loss=0.0333 avg_kappa=0.9834\n",
      "[TRAIN] iter=6340/10000 avg_loss=0.2148 avg_kappa=0.9548\n",
      "[TRAIN] iter=6350/10000 avg_loss=0.0056 avg_kappa=1.0000\n",
      "[TRAIN] iter=6360/10000 avg_loss=0.0097 avg_kappa=1.0000\n",
      "[TRAIN] iter=6370/10000 avg_loss=0.0403 avg_kappa=1.0000\n",
      "[TRAIN] iter=6380/10000 avg_loss=0.0192 avg_kappa=1.0000\n",
      "[TRAIN] iter=6390/10000 avg_loss=0.0194 avg_kappa=1.0000\n",
      "[TRAIN] iter=6400/10000 avg_loss=0.0040 avg_kappa=1.0000\n",
      "[EVAL ] iter=6400/10000 avg_loss=0.5390 kappa=0.6250\n",
      "[TRAIN] iter=6410/10000 avg_loss=0.0100 avg_kappa=1.0000\n",
      "[TRAIN] iter=6420/10000 avg_loss=0.0053 avg_kappa=1.0000\n",
      "[TRAIN] iter=6430/10000 avg_loss=0.0074 avg_kappa=1.0000\n",
      "[TRAIN] iter=6440/10000 avg_loss=0.0112 avg_kappa=1.0000\n",
      "[TRAIN] iter=6450/10000 avg_loss=0.0134 avg_kappa=1.0000\n",
      "[TRAIN] iter=6460/10000 avg_loss=0.0213 avg_kappa=0.9815\n",
      "[TRAIN] iter=6470/10000 avg_loss=0.0139 avg_kappa=1.0000\n",
      "[TRAIN] iter=6480/10000 avg_loss=0.0037 avg_kappa=1.0000\n",
      "[TRAIN] iter=6490/10000 avg_loss=0.0053 avg_kappa=1.0000\n",
      "[TRAIN] iter=6500/10000 avg_loss=0.0023 avg_kappa=1.0000\n",
      "[EVAL ] iter=6500/10000 avg_loss=0.5857 kappa=0.5475\n",
      "[TRAIN] iter=6510/10000 avg_loss=0.0034 avg_kappa=1.0000\n",
      "[TRAIN] iter=6520/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=6530/10000 avg_loss=0.0038 avg_kappa=1.0000\n",
      "[TRAIN] iter=6540/10000 avg_loss=0.0146 avg_kappa=1.0000\n",
      "[TRAIN] iter=6550/10000 avg_loss=0.0014 avg_kappa=1.0000\n",
      "[TRAIN] iter=6560/10000 avg_loss=0.0015 avg_kappa=1.0000\n",
      "[TRAIN] iter=6570/10000 avg_loss=0.0149 avg_kappa=1.0000\n",
      "[TRAIN] iter=6580/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=6590/10000 avg_loss=0.0082 avg_kappa=1.0000\n",
      "[TRAIN] iter=6600/10000 avg_loss=0.0019 avg_kappa=1.0000\n",
      "[EVAL ] iter=6600/10000 avg_loss=0.6565 kappa=0.6250\n",
      "[TRAIN] iter=6610/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=6620/10000 avg_loss=0.0019 avg_kappa=1.0000\n",
      "[TRAIN] iter=6630/10000 avg_loss=0.0028 avg_kappa=1.0000\n",
      "[TRAIN] iter=6640/10000 avg_loss=0.0022 avg_kappa=1.0000\n",
      "[TRAIN] iter=6650/10000 avg_loss=0.0012 avg_kappa=1.0000\n",
      "[TRAIN] iter=6660/10000 avg_loss=0.0019 avg_kappa=1.0000\n",
      "[TRAIN] iter=6670/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=6680/10000 avg_loss=0.0023 avg_kappa=1.0000\n",
      "[TRAIN] iter=6690/10000 avg_loss=0.0012 avg_kappa=1.0000\n",
      "[TRAIN] iter=6700/10000 avg_loss=0.0017 avg_kappa=1.0000\n",
      "[EVAL ] iter=6700/10000 avg_loss=0.6866 kappa=0.6250\n",
      "[TRAIN] iter=6710/10000 avg_loss=0.0213 avg_kappa=0.9813\n",
      "[TRAIN] iter=6720/10000 avg_loss=0.0092 avg_kappa=1.0000\n",
      "[TRAIN] iter=6730/10000 avg_loss=0.0049 avg_kappa=1.0000\n",
      "[TRAIN] iter=6740/10000 avg_loss=0.0019 avg_kappa=1.0000\n",
      "[TRAIN] iter=6750/10000 avg_loss=0.0132 avg_kappa=1.0000\n",
      "[TRAIN] iter=6760/10000 avg_loss=0.0034 avg_kappa=1.0000\n",
      "[TRAIN] iter=6770/10000 avg_loss=0.0030 avg_kappa=1.0000\n",
      "[TRAIN] iter=6780/10000 avg_loss=0.0045 avg_kappa=1.0000\n",
      "[TRAIN] iter=6790/10000 avg_loss=0.0022 avg_kappa=1.0000\n",
      "[TRAIN] iter=6800/10000 avg_loss=0.0014 avg_kappa=1.0000\n",
      "[EVAL ] iter=6800/10000 avg_loss=0.5627 kappa=0.6139\n",
      "[TRAIN] iter=6810/10000 avg_loss=0.0015 avg_kappa=1.0000\n",
      "[TRAIN] iter=6820/10000 avg_loss=0.0014 avg_kappa=1.0000\n",
      "[TRAIN] iter=6830/10000 avg_loss=0.0022 avg_kappa=1.0000\n",
      "[TRAIN] iter=6840/10000 avg_loss=0.0032 avg_kappa=1.0000\n",
      "[TRAIN] iter=6850/10000 avg_loss=0.0037 avg_kappa=1.0000\n",
      "[TRAIN] iter=6860/10000 avg_loss=0.0045 avg_kappa=1.0000\n",
      "[TRAIN] iter=6870/10000 avg_loss=0.0012 avg_kappa=1.0000\n",
      "[TRAIN] iter=6880/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=6890/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=6900/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[EVAL ] iter=6900/10000 avg_loss=0.7430 kappa=0.5851\n",
      "[TRAIN] iter=6910/10000 avg_loss=0.0037 avg_kappa=1.0000\n",
      "[TRAIN] iter=6920/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=6930/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=6940/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=6950/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=6960/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=6970/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=6980/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=6990/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=7000/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[EVAL ] iter=7000/10000 avg_loss=0.7383 kappa=0.5769\n",
      "[TRAIN] iter=7010/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=7020/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=7030/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=7040/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=7050/10000 avg_loss=0.0016 avg_kappa=1.0000\n",
      "[TRAIN] iter=7060/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=7070/10000 avg_loss=0.0014 avg_kappa=1.0000\n",
      "[TRAIN] iter=7080/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=7090/10000 avg_loss=0.0873 avg_kappa=0.9606\n",
      "[TRAIN] iter=7100/10000 avg_loss=0.0121 avg_kappa=1.0000\n",
      "[EVAL ] iter=7100/10000 avg_loss=0.7140 kappa=0.6416\n",
      "[TRAIN] iter=7110/10000 avg_loss=0.0090 avg_kappa=1.0000\n",
      "[TRAIN] iter=7120/10000 avg_loss=0.0024 avg_kappa=1.0000\n",
      "[TRAIN] iter=7130/10000 avg_loss=0.0021 avg_kappa=1.0000\n",
      "[TRAIN] iter=7140/10000 avg_loss=0.0251 avg_kappa=0.9764\n",
      "[TRAIN] iter=7150/10000 avg_loss=0.0106 avg_kappa=1.0000\n",
      "[TRAIN] iter=7160/10000 avg_loss=0.0114 avg_kappa=1.0000\n",
      "[TRAIN] iter=7170/10000 avg_loss=0.0051 avg_kappa=1.0000\n",
      "[TRAIN] iter=7180/10000 avg_loss=0.0107 avg_kappa=1.0000\n",
      "[TRAIN] iter=7190/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=7200/10000 avg_loss=0.0021 avg_kappa=1.0000\n",
      "[EVAL ] iter=7200/10000 avg_loss=0.9211 kappa=0.5851\n",
      "[TRAIN] iter=7210/10000 avg_loss=0.0311 avg_kappa=0.9811\n",
      "[TRAIN] iter=7220/10000 avg_loss=0.0068 avg_kappa=1.0000\n",
      "[TRAIN] iter=7230/10000 avg_loss=0.0035 avg_kappa=1.0000\n",
      "[TRAIN] iter=7240/10000 avg_loss=0.0210 avg_kappa=1.0000\n",
      "[TRAIN] iter=7250/10000 avg_loss=0.0023 avg_kappa=1.0000\n",
      "[TRAIN] iter=7260/10000 avg_loss=0.0128 avg_kappa=1.0000\n",
      "[TRAIN] iter=7270/10000 avg_loss=0.0129 avg_kappa=1.0000\n",
      "[TRAIN] iter=7280/10000 avg_loss=0.0058 avg_kappa=1.0000\n",
      "[TRAIN] iter=7290/10000 avg_loss=0.0363 avg_kappa=0.9794\n",
      "[TRAIN] iter=7300/10000 avg_loss=0.1475 avg_kappa=0.9648\n",
      "[EVAL ] iter=7300/10000 avg_loss=0.8112 kappa=0.7309\n",
      "[TRAIN] iter=7310/10000 avg_loss=0.0376 avg_kappa=0.9813\n",
      "[TRAIN] iter=7320/10000 avg_loss=0.0167 avg_kappa=1.0000\n",
      "[TRAIN] iter=7330/10000 avg_loss=0.0869 avg_kappa=0.9065\n",
      "[TRAIN] iter=7340/10000 avg_loss=0.0232 avg_kappa=1.0000\n",
      "[TRAIN] iter=7350/10000 avg_loss=0.0180 avg_kappa=1.0000\n",
      "[TRAIN] iter=7360/10000 avg_loss=0.0492 avg_kappa=0.9802\n",
      "[TRAIN] iter=7370/10000 avg_loss=0.0064 avg_kappa=1.0000\n",
      "[TRAIN] iter=7380/10000 avg_loss=0.0081 avg_kappa=1.0000\n",
      "[TRAIN] iter=7390/10000 avg_loss=0.0101 avg_kappa=1.0000\n",
      "[TRAIN] iter=7400/10000 avg_loss=0.0136 avg_kappa=1.0000\n",
      "[EVAL ] iter=7400/10000 avg_loss=0.8904 kappa=0.7083\n",
      "[TRAIN] iter=7410/10000 avg_loss=0.0215 avg_kappa=1.0000\n",
      "[TRAIN] iter=7420/10000 avg_loss=0.0692 avg_kappa=0.9809\n",
      "[TRAIN] iter=7430/10000 avg_loss=0.0110 avg_kappa=1.0000\n",
      "[TRAIN] iter=7440/10000 avg_loss=0.0346 avg_kappa=1.0000\n",
      "[TRAIN] iter=7450/10000 avg_loss=0.0375 avg_kappa=0.9810\n",
      "[TRAIN] iter=7460/10000 avg_loss=0.0093 avg_kappa=1.0000\n",
      "[TRAIN] iter=7470/10000 avg_loss=0.0081 avg_kappa=1.0000\n",
      "[TRAIN] iter=7480/10000 avg_loss=0.0034 avg_kappa=1.0000\n",
      "[TRAIN] iter=7490/10000 avg_loss=0.0465 avg_kappa=0.9818\n",
      "[TRAIN] iter=7500/10000 avg_loss=0.0044 avg_kappa=1.0000\n",
      "[EVAL ] iter=7500/10000 avg_loss=0.7520 kappa=0.6416\n",
      "[TRAIN] iter=7510/10000 avg_loss=0.0061 avg_kappa=1.0000\n",
      "[TRAIN] iter=7520/10000 avg_loss=0.1962 avg_kappa=0.9591\n",
      "[TRAIN] iter=7530/10000 avg_loss=0.0208 avg_kappa=1.0000\n",
      "[TRAIN] iter=7540/10000 avg_loss=0.0066 avg_kappa=1.0000\n",
      "[TRAIN] iter=7550/10000 avg_loss=0.0113 avg_kappa=1.0000\n",
      "[TRAIN] iter=7560/10000 avg_loss=0.0051 avg_kappa=1.0000\n",
      "[TRAIN] iter=7570/10000 avg_loss=0.0023 avg_kappa=1.0000\n",
      "[TRAIN] iter=7580/10000 avg_loss=0.0015 avg_kappa=1.0000\n",
      "[TRAIN] iter=7590/10000 avg_loss=0.0108 avg_kappa=1.0000\n",
      "[TRAIN] iter=7600/10000 avg_loss=0.0023 avg_kappa=1.0000\n",
      "[EVAL ] iter=7600/10000 avg_loss=0.6069 kappa=0.5851\n",
      "[TRAIN] iter=7610/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=7620/10000 avg_loss=0.0014 avg_kappa=1.0000\n",
      "[TRAIN] iter=7630/10000 avg_loss=0.0013 avg_kappa=1.0000\n",
      "[TRAIN] iter=7640/10000 avg_loss=0.0043 avg_kappa=1.0000\n",
      "[TRAIN] iter=7650/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=7660/10000 avg_loss=0.0034 avg_kappa=1.0000\n",
      "[TRAIN] iter=7670/10000 avg_loss=0.0016 avg_kappa=1.0000\n",
      "[TRAIN] iter=7680/10000 avg_loss=0.0015 avg_kappa=1.0000\n",
      "[TRAIN] iter=7690/10000 avg_loss=0.0019 avg_kappa=1.0000\n",
      "[TRAIN] iter=7700/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[EVAL ] iter=7700/10000 avg_loss=0.7437 kappa=0.5851\n",
      "[TRAIN] iter=7710/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=7720/10000 avg_loss=0.0048 avg_kappa=1.0000\n",
      "[TRAIN] iter=7730/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=7740/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=7750/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=7760/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=7770/10000 avg_loss=0.0020 avg_kappa=1.0000\n",
      "[TRAIN] iter=7780/10000 avg_loss=0.0018 avg_kappa=1.0000\n",
      "[TRAIN] iter=7790/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=7800/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[EVAL ] iter=7800/10000 avg_loss=0.8906 kappa=0.5851\n",
      "[TRAIN] iter=7810/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=7820/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=7830/10000 avg_loss=0.0015 avg_kappa=1.0000\n",
      "[TRAIN] iter=7840/10000 avg_loss=0.0050 avg_kappa=1.0000\n",
      "[TRAIN] iter=7850/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=7860/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=7870/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=7880/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=7890/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=7900/10000 avg_loss=0.0012 avg_kappa=1.0000\n",
      "[EVAL ] iter=7900/10000 avg_loss=0.9367 kappa=0.5851\n",
      "[TRAIN] iter=7910/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=7920/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=7930/10000 avg_loss=0.0019 avg_kappa=1.0000\n",
      "[TRAIN] iter=7940/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=7950/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=7960/10000 avg_loss=0.0015 avg_kappa=1.0000\n",
      "[TRAIN] iter=7970/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=7980/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=7990/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=8000/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[EVAL ] iter=8000/10000 avg_loss=1.0042 kappa=0.5851\n",
      "[TRAIN] iter=8010/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=8020/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=8030/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8040/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=8050/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=8060/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=8070/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8080/10000 avg_loss=0.0022 avg_kappa=1.0000\n",
      "[TRAIN] iter=8090/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=8100/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[EVAL ] iter=8100/10000 avg_loss=0.9240 kappa=0.5851\n",
      "[TRAIN] iter=8110/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=8120/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=8130/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=8140/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=8150/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8160/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=8170/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=8180/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=8190/10000 avg_loss=0.0001 avg_kappa=1.0000\n",
      "[TRAIN] iter=8200/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[EVAL ] iter=8200/10000 avg_loss=0.9052 kappa=0.5851\n",
      "[TRAIN] iter=8210/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8220/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8230/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=8240/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8250/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=8260/10000 avg_loss=0.0060 avg_kappa=1.0000\n",
      "[TRAIN] iter=8270/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=8280/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=8290/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8300/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[EVAL ] iter=8300/10000 avg_loss=0.8501 kappa=0.5851\n",
      "[TRAIN] iter=8310/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=8320/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=8330/10000 avg_loss=0.0036 avg_kappa=1.0000\n",
      "[TRAIN] iter=8340/10000 avg_loss=0.0012 avg_kappa=1.0000\n",
      "[TRAIN] iter=8350/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=8360/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8370/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=8380/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=8390/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=8400/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[EVAL ] iter=8400/10000 avg_loss=1.0250 kappa=0.5045\n",
      "[TRAIN] iter=8410/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=8420/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8430/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=8440/10000 avg_loss=0.0001 avg_kappa=1.0000\n",
      "[TRAIN] iter=8450/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=8460/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=8470/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=8480/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8490/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=8500/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[EVAL ] iter=8500/10000 avg_loss=0.9135 kappa=0.5851\n",
      "[TRAIN] iter=8510/10000 avg_loss=0.0027 avg_kappa=1.0000\n",
      "[TRAIN] iter=8520/10000 avg_loss=0.0001 avg_kappa=1.0000\n",
      "[TRAIN] iter=8530/10000 avg_loss=0.0002 avg_kappa=1.0000\n",
      "[TRAIN] iter=8540/10000 avg_loss=0.1298 avg_kappa=0.9843\n",
      "[TRAIN] iter=8550/10000 avg_loss=0.0673 avg_kappa=0.9826\n",
      "[TRAIN] iter=8560/10000 avg_loss=0.0504 avg_kappa=0.9796\n",
      "[TRAIN] iter=8570/10000 avg_loss=0.1431 avg_kappa=0.9612\n",
      "[TRAIN] iter=8580/10000 avg_loss=0.0826 avg_kappa=0.9806\n",
      "[TRAIN] iter=8590/10000 avg_loss=0.1124 avg_kappa=0.9640\n",
      "[TRAIN] iter=8600/10000 avg_loss=0.5474 avg_kappa=0.8204\n",
      "[EVAL ] iter=8600/10000 avg_loss=1.6165 kappa=0.4444\n",
      "[TRAIN] iter=8610/10000 avg_loss=0.0878 avg_kappa=0.9602\n",
      "[TRAIN] iter=8620/10000 avg_loss=0.2222 avg_kappa=0.9469\n",
      "[TRAIN] iter=8630/10000 avg_loss=0.2706 avg_kappa=0.8770\n",
      "[TRAIN] iter=8640/10000 avg_loss=0.1694 avg_kappa=0.7872\n",
      "[TRAIN] iter=8650/10000 avg_loss=0.0130 avg_kappa=1.0000\n",
      "[TRAIN] iter=8660/10000 avg_loss=0.0831 avg_kappa=0.9153\n",
      "[TRAIN] iter=8670/10000 avg_loss=0.1262 avg_kappa=0.9065\n",
      "[TRAIN] iter=8680/10000 avg_loss=0.1946 avg_kappa=0.9202\n",
      "[TRAIN] iter=8690/10000 avg_loss=0.1386 avg_kappa=0.9623\n",
      "[TRAIN] iter=8700/10000 avg_loss=0.0573 avg_kappa=0.9811\n",
      "[EVAL ] iter=8700/10000 avg_loss=0.7837 kappa=0.7482\n",
      "[TRAIN] iter=8710/10000 avg_loss=0.3530 avg_kappa=0.8537\n",
      "[TRAIN] iter=8720/10000 avg_loss=0.5047 avg_kappa=0.9130\n",
      "[TRAIN] iter=8730/10000 avg_loss=0.0371 avg_kappa=0.9839\n",
      "[TRAIN] iter=8740/10000 avg_loss=0.2955 avg_kappa=0.8427\n",
      "[TRAIN] iter=8750/10000 avg_loss=0.0840 avg_kappa=0.9175\n",
      "[TRAIN] iter=8760/10000 avg_loss=0.2105 avg_kappa=0.9160\n",
      "[TRAIN] iter=8770/10000 avg_loss=0.0421 avg_kappa=1.0000\n",
      "[TRAIN] iter=8780/10000 avg_loss=0.0518 avg_kappa=0.9787\n",
      "[TRAIN] iter=8790/10000 avg_loss=0.0092 avg_kappa=1.0000\n",
      "[TRAIN] iter=8800/10000 avg_loss=0.0133 avg_kappa=1.0000\n",
      "[EVAL ] iter=8800/10000 avg_loss=0.6125 kappa=0.7748\n",
      "[TRAIN] iter=8810/10000 avg_loss=0.0093 avg_kappa=1.0000\n",
      "[TRAIN] iter=8820/10000 avg_loss=0.0030 avg_kappa=1.0000\n",
      "[TRAIN] iter=8830/10000 avg_loss=0.0107 avg_kappa=1.0000\n",
      "[TRAIN] iter=8840/10000 avg_loss=0.0071 avg_kappa=1.0000\n",
      "[TRAIN] iter=8850/10000 avg_loss=0.0056 avg_kappa=1.0000\n",
      "[TRAIN] iter=8860/10000 avg_loss=0.0039 avg_kappa=1.0000\n",
      "[TRAIN] iter=8870/10000 avg_loss=0.0265 avg_kappa=1.0000\n",
      "[TRAIN] iter=8880/10000 avg_loss=0.0042 avg_kappa=1.0000\n",
      "[TRAIN] iter=8890/10000 avg_loss=0.0040 avg_kappa=1.0000\n",
      "[TRAIN] iter=8900/10000 avg_loss=0.0079 avg_kappa=1.0000\n",
      "[EVAL ] iter=8900/10000 avg_loss=0.8937 kappa=0.8190\n",
      "[TRAIN] iter=8910/10000 avg_loss=0.0123 avg_kappa=1.0000\n",
      "[TRAIN] iter=8920/10000 avg_loss=0.0198 avg_kappa=1.0000\n",
      "[TRAIN] iter=8930/10000 avg_loss=0.0039 avg_kappa=1.0000\n",
      "[TRAIN] iter=8940/10000 avg_loss=0.0022 avg_kappa=1.0000\n",
      "[TRAIN] iter=8950/10000 avg_loss=0.0030 avg_kappa=1.0000\n",
      "[TRAIN] iter=8960/10000 avg_loss=0.0075 avg_kappa=1.0000\n",
      "[TRAIN] iter=8970/10000 avg_loss=0.0084 avg_kappa=1.0000\n",
      "[TRAIN] iter=8980/10000 avg_loss=0.1601 avg_kappa=0.9820\n",
      "[TRAIN] iter=8990/10000 avg_loss=0.0276 avg_kappa=1.0000\n",
      "[TRAIN] iter=9000/10000 avg_loss=0.0154 avg_kappa=1.0000\n",
      "[EVAL ] iter=9000/10000 avg_loss=1.3034 kappa=0.6818\n",
      "[TRAIN] iter=9010/10000 avg_loss=0.0136 avg_kappa=1.0000\n",
      "[TRAIN] iter=9020/10000 avg_loss=0.0133 avg_kappa=1.0000\n",
      "[TRAIN] iter=9030/10000 avg_loss=0.0055 avg_kappa=1.0000\n",
      "[TRAIN] iter=9040/10000 avg_loss=0.0188 avg_kappa=1.0000\n",
      "[TRAIN] iter=9050/10000 avg_loss=0.0023 avg_kappa=1.0000\n",
      "[TRAIN] iter=9060/10000 avg_loss=0.0031 avg_kappa=1.0000\n",
      "[TRAIN] iter=9070/10000 avg_loss=0.0022 avg_kappa=1.0000\n",
      "[TRAIN] iter=9080/10000 avg_loss=0.0059 avg_kappa=1.0000\n",
      "[TRAIN] iter=9090/10000 avg_loss=0.0028 avg_kappa=1.0000\n",
      "[TRAIN] iter=9100/10000 avg_loss=0.0045 avg_kappa=1.0000\n",
      "[EVAL ] iter=9100/10000 avg_loss=0.9799 kappa=0.6250\n",
      "[TRAIN] iter=9110/10000 avg_loss=0.0028 avg_kappa=1.0000\n",
      "[TRAIN] iter=9120/10000 avg_loss=0.0638 avg_kappa=0.9832\n",
      "[TRAIN] iter=9130/10000 avg_loss=0.0013 avg_kappa=1.0000\n",
      "[TRAIN] iter=9140/10000 avg_loss=0.0052 avg_kappa=1.0000\n",
      "[TRAIN] iter=9150/10000 avg_loss=0.0031 avg_kappa=1.0000\n",
      "[TRAIN] iter=9160/10000 avg_loss=0.1021 avg_kappa=0.9805\n",
      "[TRAIN] iter=9170/10000 avg_loss=0.0193 avg_kappa=1.0000\n",
      "[TRAIN] iter=9180/10000 avg_loss=0.0986 avg_kappa=0.9675\n",
      "[TRAIN] iter=9190/10000 avg_loss=0.0082 avg_kappa=1.0000\n",
      "[TRAIN] iter=9200/10000 avg_loss=0.0138 avg_kappa=1.0000\n",
      "[EVAL ] iter=9200/10000 avg_loss=0.9929 kappa=0.6818\n",
      "[TRAIN] iter=9210/10000 avg_loss=0.0042 avg_kappa=1.0000\n",
      "[TRAIN] iter=9220/10000 avg_loss=0.0075 avg_kappa=1.0000\n",
      "[TRAIN] iter=9230/10000 avg_loss=0.0632 avg_kappa=0.9591\n",
      "[TRAIN] iter=9240/10000 avg_loss=0.0188 avg_kappa=1.0000\n",
      "[TRAIN] iter=9250/10000 avg_loss=0.0080 avg_kappa=1.0000\n",
      "[TRAIN] iter=9260/10000 avg_loss=0.0045 avg_kappa=1.0000\n",
      "[TRAIN] iter=9270/10000 avg_loss=0.0121 avg_kappa=1.0000\n",
      "[TRAIN] iter=9280/10000 avg_loss=0.0163 avg_kappa=1.0000\n",
      "[TRAIN] iter=9290/10000 avg_loss=0.0040 avg_kappa=1.0000\n",
      "[TRAIN] iter=9300/10000 avg_loss=0.0020 avg_kappa=1.0000\n",
      "[EVAL ] iter=9300/10000 avg_loss=0.7973 kappa=0.7287\n",
      "[TRAIN] iter=9310/10000 avg_loss=0.0065 avg_kappa=1.0000\n",
      "[TRAIN] iter=9320/10000 avg_loss=0.0031 avg_kappa=1.0000\n",
      "[TRAIN] iter=9330/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=9340/10000 avg_loss=0.0017 avg_kappa=1.0000\n",
      "[TRAIN] iter=9350/10000 avg_loss=0.0016 avg_kappa=1.0000\n",
      "[TRAIN] iter=9360/10000 avg_loss=0.0023 avg_kappa=1.0000\n",
      "[TRAIN] iter=9370/10000 avg_loss=0.0015 avg_kappa=1.0000\n",
      "[TRAIN] iter=9380/10000 avg_loss=0.0039 avg_kappa=1.0000\n",
      "[TRAIN] iter=9390/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=9400/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[EVAL ] iter=9400/10000 avg_loss=1.1159 kappa=0.6818\n",
      "[TRAIN] iter=9410/10000 avg_loss=0.0015 avg_kappa=1.0000\n",
      "[TRAIN] iter=9420/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=9430/10000 avg_loss=0.0036 avg_kappa=1.0000\n",
      "[TRAIN] iter=9440/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=9450/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=9460/10000 avg_loss=0.0020 avg_kappa=1.0000\n",
      "[TRAIN] iter=9470/10000 avg_loss=0.0014 avg_kappa=1.0000\n",
      "[TRAIN] iter=9480/10000 avg_loss=0.0024 avg_kappa=1.0000\n",
      "[TRAIN] iter=9490/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=9500/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[EVAL ] iter=9500/10000 avg_loss=1.1532 kappa=0.6818\n",
      "[TRAIN] iter=9510/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=9520/10000 avg_loss=0.0023 avg_kappa=1.0000\n",
      "[TRAIN] iter=9530/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=9540/10000 avg_loss=0.0007 avg_kappa=1.0000\n",
      "[TRAIN] iter=9550/10000 avg_loss=0.0013 avg_kappa=1.0000\n",
      "[TRAIN] iter=9560/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=9570/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=9580/10000 avg_loss=0.0085 avg_kappa=1.0000\n",
      "[TRAIN] iter=9590/10000 avg_loss=0.0436 avg_kappa=0.9831\n",
      "[TRAIN] iter=9600/10000 avg_loss=0.0124 avg_kappa=1.0000\n",
      "[EVAL ] iter=9600/10000 avg_loss=1.1007 kappa=0.5021\n",
      "[TRAIN] iter=9610/10000 avg_loss=0.0077 avg_kappa=1.0000\n",
      "[TRAIN] iter=9620/10000 avg_loss=0.0132 avg_kappa=1.0000\n",
      "[TRAIN] iter=9630/10000 avg_loss=0.0032 avg_kappa=1.0000\n",
      "[TRAIN] iter=9640/10000 avg_loss=0.0018 avg_kappa=1.0000\n",
      "[TRAIN] iter=9650/10000 avg_loss=0.0275 avg_kappa=0.9819\n",
      "[TRAIN] iter=9660/10000 avg_loss=0.0081 avg_kappa=1.0000\n",
      "[TRAIN] iter=9670/10000 avg_loss=0.0079 avg_kappa=1.0000\n",
      "[TRAIN] iter=9680/10000 avg_loss=0.0070 avg_kappa=1.0000\n",
      "[TRAIN] iter=9690/10000 avg_loss=0.0012 avg_kappa=1.0000\n",
      "[TRAIN] iter=9700/10000 avg_loss=0.0041 avg_kappa=1.0000\n",
      "[EVAL ] iter=9700/10000 avg_loss=0.7592 kappa=0.6653\n",
      "[TRAIN] iter=9710/10000 avg_loss=0.0013 avg_kappa=1.0000\n",
      "[TRAIN] iter=9720/10000 avg_loss=0.0071 avg_kappa=1.0000\n",
      "[TRAIN] iter=9730/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=9740/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=9750/10000 avg_loss=0.0049 avg_kappa=1.0000\n",
      "[TRAIN] iter=9760/10000 avg_loss=0.0061 avg_kappa=1.0000\n",
      "[TRAIN] iter=9770/10000 avg_loss=0.0046 avg_kappa=1.0000\n",
      "[TRAIN] iter=9780/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=9790/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=9800/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[EVAL ] iter=9800/10000 avg_loss=0.9234 kappa=0.6653\n",
      "[TRAIN] iter=9810/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=9820/10000 avg_loss=0.0016 avg_kappa=1.0000\n",
      "[TRAIN] iter=9830/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=9840/10000 avg_loss=0.0006 avg_kappa=1.0000\n",
      "[TRAIN] iter=9850/10000 avg_loss=0.0003 avg_kappa=1.0000\n",
      "[TRAIN] iter=9860/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=9870/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=9880/10000 avg_loss=0.0008 avg_kappa=1.0000\n",
      "[TRAIN] iter=9890/10000 avg_loss=0.0245 avg_kappa=1.0000\n",
      "[TRAIN] iter=9900/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[EVAL ] iter=9900/10000 avg_loss=1.0113 kappa=0.6653\n",
      "[TRAIN] iter=9910/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=9920/10000 avg_loss=0.0028 avg_kappa=1.0000\n",
      "[TRAIN] iter=9930/10000 avg_loss=0.0026 avg_kappa=1.0000\n",
      "[TRAIN] iter=9940/10000 avg_loss=0.0005 avg_kappa=1.0000\n",
      "[TRAIN] iter=9950/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[TRAIN] iter=9960/10000 avg_loss=0.0010 avg_kappa=1.0000\n",
      "[TRAIN] iter=9970/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=9980/10000 avg_loss=0.0011 avg_kappa=1.0000\n",
      "[TRAIN] iter=9990/10000 avg_loss=0.0004 avg_kappa=1.0000\n",
      "[TRAIN] iter=10000/10000 avg_loss=0.0009 avg_kappa=1.0000\n",
      "[EVAL ] iter=10000/10000 avg_loss=0.8789 kappa=0.6653\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "from torchvision.models import resnet34, resnet50\n",
    "\n",
    "# 如果你有自定义 transforms（保持你原来的 API）\n",
    "import transforms as trans   # 若没有这份文件，可自行改用 torchvision.transforms\n",
    "\n",
    "# ========= 基本配置 =========\n",
    "batchsize    = 4\n",
    "oct_img_size = [512, 512]\n",
    "image_size   = 256\n",
    "iters        = 10000\n",
    "val_ratio    = 0.2\n",
    "trainset_root = \"/home/yanggq/project/grading/Glaucoma_grading/training/multi-modality_images\"\n",
    "label_xlsx    = \"/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx\"\n",
    "num_workers   = 4\n",
    "init_lr       = 1e-4\n",
    "save_dir      = \"trained_models_torch\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ========= 数据集 =========\n",
    "class GAMMA_sub1_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    输出:\n",
    "      fundus_img: uint8, shape (3, H, W) - RGB\n",
    "      oct_img   : uint8, shape (D, H, W) - 灰度体数据 (把 D 当做通道数用在 2D ResNet 上)\n",
    "      label     : int64 标量（0..C-1）\n",
    "    \"\"\"\n",
    "    def __init__(self, img_transforms, oct_transforms, dataset_root,\n",
    "                 label_file='', filelists=None, num_classes=3, mode='train'):\n",
    "        self.dataset_root   = dataset_root\n",
    "        self.img_transforms = img_transforms\n",
    "        self.oct_transforms = oct_transforms\n",
    "        self.mode           = mode.lower()\n",
    "        self.num_classes    = num_classes\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            # 你原始脚本从 xlsx 里读 one-hot/prob 向量，这里保持一致\n",
    "            # 注意：确保读到的是 float 数组\n",
    "            label_map = {\n",
    "                int(row['data']): np.asarray(row[1:].values, dtype=np.float32)\n",
    "                for _, row in pd.read_excel(label_file).iterrows()\n",
    "            }\n",
    "            self.file_list = [[f, label_map[int(f)]] for f in os.listdir(dataset_root)]\n",
    "        else:\n",
    "            self.file_list = [[f, None] for f in os.listdir(dataset_root)]\n",
    "\n",
    "        if filelists is not None:\n",
    "            name_set = set(filelists)\n",
    "            self.file_list = [it for it in self.file_list if it[0] in name_set]\n",
    "\n",
    "    def _oct_sort_key(self, name: str):\n",
    "        # 你原脚本用 int(x.strip(\"_\")[0]) 会按第一个字符排序，10 与 2 会乱序\n",
    "        stem = os.path.splitext(name)[0]\n",
    "        m = re.search(r'(\\d+)$', stem)\n",
    "        return int(m.group(1)) if m else stem  # 更稳妥\n",
    "        # 参考你原代码位置：oct_series_list 的排序逻辑。:contentReference[oaicite:3]{index=3}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_index, label_vec = self.file_list[idx]\n",
    "\n",
    "        fundus_img_path = os.path.join(self.dataset_root, real_index, real_index + \".jpg\")\n",
    "        series_dir = os.path.join(self.dataset_root, real_index, real_index)\n",
    "        oct_series_list = sorted(os.listdir(series_dir), key=self._oct_sort_key)\n",
    "\n",
    "        fundus_img = cv2.imread(fundus_img_path)[:, :, ::-1]  # BGR->RGB\n",
    "        # 装载一组 OCT 切片\n",
    "        oct0 = cv2.imread(os.path.join(series_dir, oct_series_list[0]), cv2.IMREAD_GRAYSCALE)\n",
    "        D, H, W = len(oct_series_list), oct0.shape[0], oct0.shape[1]\n",
    "        oct_img = np.zeros((D, H, W, 1), dtype=\"uint8\")\n",
    "        for k, p in enumerate(oct_series_list):\n",
    "            oct_img[k] = cv2.imread(os.path.join(series_dir, p), cv2.IMREAD_GRAYSCALE)[..., np.newaxis]\n",
    "\n",
    "        # 可选的图像增强\n",
    "        if self.img_transforms is not None:\n",
    "            fundus_img = self.img_transforms(fundus_img)\n",
    "        if self.oct_transforms is not None:\n",
    "            oct_img = self.oct_transforms(oct_img)\n",
    "\n",
    "        # NHWC -> NCHW\n",
    "        fundus_img = fundus_img.transpose(2, 0, 1)  # (H,W,C)->(C,H,W)\n",
    "        oct_img    = oct_img.squeeze(-1)            # (D,H,W,1)->(D,H,W)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return fundus_img, oct_img, real_index\n",
    "\n",
    "        # —— 标签：只 argmax 一次，返回 np.int64 标量（修复你原代码的“双重 argmax”问题）——\n",
    "        # 参考处：你原脚本 L61-L64 同时做了 label.argmax() 和 np.argmax(label)，会出错。:contentReference[oaicite:4]{index=4}\n",
    "        class_id = np.int64(np.argmax(label_vec))\n",
    "        return fundus_img, oct_img, class_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "# ========= collate：显式堆叠，避免默认逻辑把标签搞坏 =========\n",
    "def my_collate(batch):\n",
    "    f_list, o_list, y_list = zip(*batch)\n",
    "    f = np.stack(f_list, axis=0).astype('uint8')     # [N,3,H,W]\n",
    "    o = np.stack(o_list, axis=0).astype('uint8')     # [N,D,H,W]\n",
    "    y = np.asarray(y_list, dtype=np.int64)           # [N]\n",
    "    return f, o, y\n",
    "\n",
    "# ========= transforms（按你原脚本）=========\n",
    "img_train_transforms = trans.Compose([\n",
    "    trans.RandomResizedCrop(image_size, scale=(0.90, 1.1), ratio=(0.90, 1.1)),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "    trans.RandomRotation(30),\n",
    "])\n",
    "oct_train_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "])\n",
    "img_val_transforms = trans.Compose([\n",
    "    trans.CropCenterSquare(),\n",
    "    trans.Resize((image_size, image_size)),\n",
    "])\n",
    "oct_val_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size),\n",
    "])\n",
    "\n",
    "# ========= 划分数据 =========\n",
    "filelists = os.listdir(trainset_root)\n",
    "#train_filelists, val_filelists = train_test_split(filelists, test_size=val_ratio, random_state=12)\n",
    "\n",
    "# 最后 20 个作为测试集\n",
    "val_filelists = filelists[-20:]\n",
    "# 其余的作为训练集\n",
    "train_filelists = filelists[:-20]\n",
    "\n",
    "print(f\"Total Nums: {len(filelists)}, train: {len(train_filelists)}, val: {len(val_filelists)}\")\n",
    "\n",
    "\n",
    "train_dataset = GAMMA_sub1_dataset(dataset_root=trainset_root, \n",
    "                                   img_transforms=img_train_transforms,\n",
    "                                   oct_transforms=oct_train_transforms,\n",
    "                                   filelists=train_filelists,\n",
    "                                   label_file=label_xlsx)\n",
    "\n",
    "val_dataset = GAMMA_sub1_dataset(dataset_root=trainset_root, \n",
    "                                 img_transforms=img_val_transforms,\n",
    "                                 oct_transforms=oct_val_transforms,\n",
    "                                 filelists=val_filelists,\n",
    "                                 label_file=label_xlsx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True,\n",
    "                          num_workers=num_workers, collate_fn=my_collate, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batchsize, shuffle=False,\n",
    "                          num_workers=num_workers, collate_fn=my_collate, pin_memory=True)\n",
    "\n",
    "# ========= 模型（PyTorch 版）=========\n",
    "class ModelRes34(nn.Module):\n",
    "    \"\"\"\n",
    "    两分支：\n",
    "      - fundus_branch: resnet34 输入 3 通道\n",
    "      - oct_branch   : resnet34 输入 256 通道（把 OCT D 当通道）\n",
    "      - 拼接后接 linear 输出 3 类\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.fundus_branch = resnet34(weights=\"IMAGENET1K_V1\")  # 预训练\n",
    "        self.oct_branch    = resnet34(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "        # 去掉原 fc，改成输出特征\n",
    "        self.fundus_branch.fc = nn.Identity()\n",
    "        self.oct_branch.fc    = nn.Identity()\n",
    "\n",
    "        # 替换 OCT 分支第一层为 256 输入通道（与你 Paddle 版一致）:contentReference[oaicite:5]{index=5}\n",
    "        self.oct_branch.conv1 = nn.Conv2d(256, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # resnet34 的全局池化+fc 前输出 512 维；两分支拼接后变 1024\n",
    "        self.fc = nn.Linear(512 * 2, num_classes)\n",
    "\n",
    "    def forward(self, fundus_img, oct_img):\n",
    "        # fundus_img: [N,3,H,W] float\n",
    "        # oct_img   : [N,256,H,W] float\n",
    "        b1 = self.fundus_branch(fundus_img)  # [N,512]\n",
    "        b2 = self.oct_branch(oct_img)        # [N,512]\n",
    "        logit = self.fc(torch.cat([b1, b2], dim=1))  # [N,3]\n",
    "        return logit\n",
    "\n",
    "model = ModelRes34(num_classes=3).to(device)\n",
    "\n",
    "# ========= 优化器 / 损失 =========\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ========= 训练 / 验证 =========\n",
    "def tensorize_batch(batch):\n",
    "    f, o, y = batch  # numpy\n",
    "    # 转 float32 Tensor；归一化到 [0,1]\n",
    "    fundus = torch.from_numpy(f).float().div_(255.0).to(device, non_blocking=True)  # [N,3,H,W]\n",
    "    octv   = torch.from_numpy(o).float().div_(255.0).to(device, non_blocking=True)  # [N,D,H,W]\n",
    "    # 把 D 作为通道，输入 2D ResNet：[N,256,H,W]\n",
    "    # 你的 Dataset 已经输出 [D,H,W]，collate 后是 [N,D,H,W]，无需再转置\n",
    "    labels = torch.from_numpy(y).long().to(device, non_blocking=True)               # [N]\n",
    "    return fundus, octv, labels\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    preds_all, gts_all = [], []\n",
    "    for batch in val_loader:\n",
    "        fundus, octv, labels = tensorize_batch(batch)\n",
    "        logits = model(fundus, octv)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        gts   = labels.cpu().numpy()\n",
    "        preds_all.append(preds); gts_all.append(gts)\n",
    "    preds_all = np.concatenate(preds_all, 0)\n",
    "    gts_all   = np.concatenate(gts_all, 0)\n",
    "    kappa = cohen_kappa_score(preds_all, gts_all, weights='quadratic')\n",
    "    return float(np.mean(losses)), float(kappa)\n",
    "\n",
    "def train(num_iters=iters, log_interval=10, eval_interval=100):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.train()\n",
    "    best_kappa = -1e9\n",
    "    avg_loss_buf = []\n",
    "    kappa_buf_p, kappa_buf_g = [], []\n",
    "\n",
    "    it = 0\n",
    "    while it < num_iters:\n",
    "        for batch in train_loader:\n",
    "            it += 1\n",
    "            fundus, octv, labels = tensorize_batch(batch)\n",
    "\n",
    "            logits = model(fundus, octv)  # [N,3]\n",
    "            # 断言标签范围（你之前的致命问题）\n",
    "            with torch.no_grad():\n",
    "                lb_min, lb_max = int(labels.min().item()), int(labels.max().item())\n",
    "                assert 0 <= lb_min and lb_max < logits.size(1), \\\n",
    "                    f\"label out of range [{lb_min},{lb_max}] vs C={logits.size(1)}\"\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            avg_loss_buf.append(loss.item())\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                gts  = labels.cpu().numpy()\n",
    "                kappa_buf_p.append(pred); kappa_buf_g.append(gts)\n",
    "\n",
    "            if it % log_interval == 0:\n",
    "                avg_loss = float(np.mean(avg_loss_buf)); avg_loss_buf.clear()\n",
    "                p = np.concatenate(kappa_buf_p, 0); g = np.concatenate(kappa_buf_g, 0)\n",
    "                kappa = cohen_kappa_score(p, g, weights='quadratic')\n",
    "                kappa_buf_p.clear(); kappa_buf_g.clear()\n",
    "                print(f\"[TRAIN] iter={it}/{num_iters} avg_loss={avg_loss:.4f} avg_kappa={kappa:.4f}\")\n",
    "\n",
    "            if it % eval_interval == 0:\n",
    "                vloss, vkappa = evaluate()\n",
    "                print(f\"[EVAL ] iter={it}/{num_iters} avg_loss={vloss:.4f} kappa={vkappa:.4f}\")\n",
    "                if vkappa >= best_kappa:\n",
    "                    best_kappa = vkappa\n",
    "                    tag = f\"best_model_{best_kappa:.4f}\"\n",
    "                    out_dir = os.path.join(save_dir, tag)\n",
    "                    os.makedirs(out_dir, exist_ok=True)\n",
    "                    torch.save(model.state_dict(), os.path.join(out_dir, \"model.pt\"))\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(out_dir, \"optimizer.pt\"))\n",
    "                    print(f\"[SAVE ] {out_dir}\")\n",
    "                model.train()\n",
    "\n",
    "            if it >= num_iters:\n",
    "                break\n",
    "\n",
    "# ========= 先抽查一个 batch，确认标签健康 =========\n",
    "f0, o0, y0 = next(iter(train_loader))\n",
    "print(\"labels sample:\", y0, \"dtype:\", y0.dtype, \"shape:\", y0.shape)  # 应为 int64、一维、0..2\n",
    "\n",
    "# ========= 开始训练 =========\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ce879-bfa6-4853-a6c4-09cdcdff21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer_torch.py\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ==== 配置 ====\n",
    "image_size   = 256\n",
    "oct_img_size = [512, 512]\n",
    "num_classes  = 3\n",
    "\n",
    "# 路径（按需修改）\n",
    "best_model_path = \"/home/yanggq/project/grading/GlaucomaRecognition-main/CodeOfTask1/trained_models_torch/best_model_0.7523/model.pt\"  # PyTorch 权重\n",
    "testset_root    = \"/home/yanggq/project/grading/Glaucoma_grading/training/multi-modality_images\"                    # 测试数据根目录\n",
    "\n",
    "# ==== 轻量 transforms（与你之前的一致风格）====\n",
    "import transforms as trans\n",
    "img_test_transforms = trans.Compose([\n",
    "    trans.CropCenterSquare(),\n",
    "    trans.Resize((image_size, image_size)),\n",
    "])\n",
    "oct_test_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size),\n",
    "])\n",
    "\n",
    "# ==== 测试数据集 ====\n",
    "class GAMMA_sub1_dataset_test(Dataset):\n",
    "    \"\"\"\n",
    "    输出:\n",
    "      fundus_img: uint8, (3, H, W)  RGB\n",
    "      oct_img   : uint8, (D, H, W)  灰度体\n",
    "      idx       : 样本 ID (str)\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_root, img_transforms=None, oct_transforms=None):\n",
    "        self.dataset_root   = dataset_root\n",
    "        self.img_transforms = img_transforms\n",
    "        self.oct_transforms = oct_transforms\n",
    "        self.file_list = sorted(os.listdir(dataset_root))\n",
    "\n",
    "    def _oct_sort_key(self, name: str):\n",
    "        stem = os.path.splitext(name)[0]\n",
    "        m = re.search(r'(\\d+)$', stem)\n",
    "        return int(m.group(1)) if m else stem\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_index = self.file_list[idx]\n",
    "        fundus_img_path = os.path.join(self.dataset_root, real_index, real_index + \".jpg\")\n",
    "        series_dir = os.path.join(self.dataset_root, real_index, real_index)\n",
    "        oct_series_list = sorted(os.listdir(series_dir), key=self._oct_sort_key)\n",
    "\n",
    "        # 读图\n",
    "        fundus_img = cv2.imread(fundus_img_path)[:, :, ::-1]  # BGR->RGB\n",
    "        oct0 = cv2.imread(os.path.join(series_dir, oct_series_list[0]), cv2.IMREAD_GRAYSCALE)\n",
    "        D, H, W = len(oct_series_list), oct0.shape[0], oct0.shape[1]\n",
    "        oct_img = np.zeros((D, H, W, 1), dtype=\"uint8\")\n",
    "        for k, p in enumerate(oct_series_list):\n",
    "            oct_img[k] = cv2.imread(os.path.join(series_dir, p), cv2.IMREAD_GRAYSCALE)[..., np.newaxis]\n",
    "\n",
    "        # transforms\n",
    "        if self.img_transforms is not None:\n",
    "            fundus_img = self.img_transforms(fundus_img)\n",
    "        if self.oct_transforms is not None:\n",
    "            oct_img = self.oct_transforms(oct_img)\n",
    "\n",
    "        # NHWC->CHW / DHWC->DHW\n",
    "        fundus_img = fundus_img.transpose(2, 0, 1)\n",
    "        oct_img    = oct_img.squeeze(-1)\n",
    "\n",
    "        return fundus_img, oct_img, real_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "# ===== collate（显式堆叠，保持 dtype）=====\n",
    "def collate_test(batch):\n",
    "    f_list, o_list, idx_list = zip(*batch)\n",
    "    f = np.stack(f_list, axis=0).astype(\"uint8\")  # [N,3,H,W]\n",
    "    o = np.stack(o_list, axis=0).astype(\"uint8\")  # [N,D,H,W]\n",
    "    return f, o, list(idx_list)\n",
    "\n",
    "# ===== 模型（与你训练用的两分支 ResNet34 对齐）=====\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.fundus_branch = resnet34(weights=\"IMAGENET1K_V1\")\n",
    "        self.oct_branch    = resnet34(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "        # 去掉 fc，只取 512 维特征\n",
    "        self.fundus_branch.fc = nn.Identity()\n",
    "        self.oct_branch.fc    = nn.Identity()\n",
    "\n",
    "        # OCT 分支第一层改为 256 输入通道（把 D 当通道）\n",
    "        self.oct_branch.conv1 = nn.Conv2d(256, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        self.fc = nn.Linear(512 * 2, num_classes)\n",
    "\n",
    "    def forward(self, fundus_img, oct_img):\n",
    "        b1 = self.fundus_branch(fundus_img)  # [N,512]\n",
    "        b2 = self.oct_branch(oct_img)        # [N,512]\n",
    "        return self.fc(torch.cat([b1, b2], dim=1))  # [N, num_classes]\n",
    "\n",
    "# ===== 推理 =====\n",
    "def tensorize_batch(batch, device):\n",
    "    f, o, idx_list = batch\n",
    "    fundus = torch.from_numpy(f).float().div_(255.0).to(device, non_blocking=True)  # [N,3,H,W]\n",
    "    octv   = torch.from_numpy(o).float().div_(255.0).to(device, non_blocking=True)  # [N,D,H,W]\n",
    "    return fundus, octv, idx_list\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    # 数据\n",
    "    test_dataset = GAMMA_sub1_dataset_test(\n",
    "        dataset_root=testset_root,\n",
    "        img_transforms=img_test_transforms,\n",
    "        oct_transforms=oct_test_transforms\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False,\n",
    "                             num_workers=2, collate_fn=collate_test, pin_memory=True)\n",
    "\n",
    "    # 模型 & 权重\n",
    "    model = Model(num_classes=num_classes).to(device)\n",
    "    state = torch.load(best_model_path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    rows = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            fundus, octv, idx_list = tensorize_batch(batch, device)\n",
    "            logits = model(fundus, octv)                   # [N,3]\n",
    "            preds  = torch.argmax(logits, dim=1).cpu().numpy()  # [N]\n",
    "\n",
    "            # 组装提交格式\n",
    "            for i, idx in enumerate(idx_list):\n",
    "                p = int(preds[i])\n",
    "                rows.append([\n",
    "                    idx,\n",
    "                    int(p == 0),  # non\n",
    "                    int(p == 1),  # early\n",
    "                    int(p == 2),  # mid_advanced\n",
    "                ])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"data\", \"non\", \"early\", \"mid_advanced\"])\n",
    "    df.to_csv(\"Classification_Results.csv\", index=False)\n",
    "    print(\"Saved: Classification_Results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6adbab-854c-4a4b-8142-8a511d00d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# 读取文件\n",
    "gt_df = pd.read_csv(\"/home/yanggq/project/grading/GlaucomaRecognition-main/CodeOfTask1/Classification_Results.csv\")  # ground truth\n",
    "pred_df = pd.read_excel(\"/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx\")  # predictions\n",
    "\n",
    "# 提取标签（取最大概率对应的类别）\n",
    "gt_labels = gt_df[['non', 'early', 'mid_advanced']].values.argmax(axis=1)\n",
    "pred_labels = pred_df[['non', 'early', 'mid_advanced']].values.argmax(axis=1)\n",
    "\n",
    "# 计算 Cohen's Kappa\n",
    "kappa = cohen_kappa_score(gt_labels, pred_labels)\n",
    "\n",
    "print(\"Cohen's Kappa:\", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73704a0d-53a5-41c8-ae82-d4159675acb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9670, Cohen's Kappa = 0.9470\n",
      "Saved per-sample comparison -> per_sample_compare.csv\n",
      "Wrong samples (head):\n",
      "    data  gt_label  pred_label  is_correct\n",
      "60    70         2           1           0\n",
      "80    90         2           1           0\n",
      "87    97         2           1           0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# 路径按需修改\n",
    "gt_path   = \"/home/yanggq/project/grading/GlaucomaRecognition-main/CodeOfTask1/Classification_Results.csv\"     # 真实标注（Excel）\n",
    "pred_path = \"/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx\"            # 你的预测（CSV）\n",
    "out_path  = \"per_sample_compare.csv\"                # 输出逐样本对比\n",
    "\n",
    "# 1) 读取\n",
    "gt_df   = pd.read_csv(gt_path)                    # 列: data, non, early, mid_advanced\n",
    "pred_df = pd.read_excel(pred_path)                    # 列: data, non, early, mid_advanced\n",
    "\n",
    "# 2) 按 data 对齐（只保留两边都出现过的样本）\n",
    "cols = [\"data\", \"non\", \"early\", \"mid_advanced\"]\n",
    "df = gt_df[cols].merge(pred_df[cols], on=\"data\", suffixes=(\"_gt\", \"_pred\"))\n",
    "\n",
    "# 3) 计算逐样本标签与是否正确\n",
    "gt_labels  = df[[\"non_gt\", \"early_gt\", \"mid_advanced_gt\"]].to_numpy().argmax(axis=1)\n",
    "pred_labels= df[[\"non_pred\",\"early_pred\",\"mid_advanced_pred\"]].to_numpy().argmax(axis=1)\n",
    "\n",
    "per_sample = pd.DataFrame({\n",
    "    \"data\": df[\"data\"],\n",
    "    \"gt_label\":  gt_labels,\n",
    "    \"pred_label\":pred_labels,\n",
    "    \"is_correct\": (gt_labels == pred_labels).astype(int)  # 1=正确，0=错误\n",
    "})\n",
    "\n",
    "# 4) 统计指标（可选）\n",
    "acc   = per_sample[\"is_correct\"].mean()\n",
    "kappa = cohen_kappa_score(gt_labels, pred_labels)\n",
    "print(f\"Accuracy = {acc:.4f}, Cohen's Kappa = {kappa:.4f}\")\n",
    "\n",
    "# 5) 保存逐样本对比\n",
    "per_sample.to_csv(out_path, index=False)\n",
    "print(f\"Saved per-sample comparison -> {out_path}\")\n",
    "\n",
    "# 想看错误样本：\n",
    "errors = per_sample.query(\"is_correct == 0\")\n",
    "print(\"Wrong samples (head):\")\n",
    "print(errors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe005fcf-7c20-4beb-b662-78d2e54060d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-AUC: 0.9006438029109599\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 读取CSV文件\n",
    "gt_path   = \"/home/yanggq/project/grading/GlaucomaRecognition-main/CodeOfTask1/Classification_Results2.csv\"     # 真实标注（Excel）\n",
    "pred_path = \"/home/yanggq/project/grading/Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx\"            # 你的预测（CSV）\n",
    "# 1) 读取\n",
    "gt_df   = pd.read_csv(gt_path)                    # 列: data, non, early, mid_advanced\n",
    "pred_df = pd.read_excel(pred_path)                    # 列: data, non, early, mid_advanced\n",
    "\n",
    "# 提取真实标签和预测概率\n",
    "y_true = gt_df[['non', 'early', 'mid_advanced']].values\n",
    "y_pred = pred_df[['non', 'early', 'mid_advanced']].values\n",
    "\n",
    "# 计算 macro-AUC\n",
    "macro_auc = roc_auc_score(y_true, y_pred, average=\"macro\", multi_class=\"ovr\")\n",
    "print(\"Macro-AUC:\", macro_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5874de-7339-4e43-b6e3-fc4f93f5cf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
